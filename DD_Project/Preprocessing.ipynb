{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "### Time Cleaning\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "### Other normal libraries\n",
    "import logging\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "### Import User Defined functions\n",
    "import source.read_tickers_and_isins as URTI\n",
    "import source.get_directors_dealings as UGDD\n",
    "import source.preprocess_directors_dealings as UPDD\n",
    "import source.preprocess_timeseries as UPTS\n",
    "import source.preprocess_timeseries_from_excel as UPTFE\n",
    "import source.get_market_data as UGMD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "### Set logging\n",
    "logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%d/%m/%Y %H:%M:%S')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set flags for what will be handled\n",
    "NAME = \"Knudsen\" # \"Niedermayer\"\n",
    "#NAME = \"Niedermayer\"\n",
    "prepare_and_download = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Constants:\n",
    "## Different Parameters depending on the setting\n",
    "if NAME == \"Knudsen\":\n",
    "    no_https = False\n",
    "    to_date_name = \"DATE/TIME (DS End Date)\"\n",
    "    STOCK_EXCHANGE = \"Nasdaq\"\n",
    "    n_input_files = 7\n",
    "    _ticker = '%5EIXIC'\n",
    "elif NAME == \"Niedermayer\":\n",
    "    no_https = True\n",
    "    to_date_name = \"DATE/TIME (DS End Date)\"\n",
    "    STOCK_EXCHANGE = \"NYSE\"\n",
    "    n_input_files = 4\n",
    "    _ticker = \"%5Enya\"\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "## Which files to be handled\n",
    "INPUT_FILE = f'input_data/{NAME}/{STOCK_EXCHANGE} Composite 16.3.2022 plus dead firms - {NAME}.xlsx'\n",
    "TIMESERIES_FILES = [f'input_data/{NAME}/{STOCK_EXCHANGE} Composite 16.3.2022 plus dead firms - {NAME} - RI - Part {i}.xlsx' for i in range(1,n_input_files+1)]\n",
    "\n",
    "# Locations to store stuff and stuff\n",
    "DATA_LOCATION = f'data/{NAME}/'\n",
    "DATA_LOCATION_INSIDER_RAW = DATA_LOCATION + 'raw/insider/'\n",
    "DATA_LOCATION_INSIDER_PROCESSED = DATA_LOCATION + 'processed/insider/'\n",
    "DATA_LOCATION_TIME_SERIES_RAW = DATA_LOCATION + 'raw/timeseries/'\n",
    "DATA_LOCATION_TIME_SERIES_PROCESSED = DATA_LOCATION + 'processed/timeseries/'\n",
    "DATA_LOCATION_RI = DATA_LOCATION + 'processed/RI/'\n",
    "DATA_LOCATION_RI_interpolate  = DATA_LOCATION + 'processed/RI_interpolate/'\n",
    "DATA_LOCATION_RI_discard = DATA_LOCATION + 'processed/RI_discard/'\n",
    "DATA_LOCATION_MARKET = DATA_LOCATION + 'raw/market/'\n",
    "\n",
    "# Create folders if they are not present\n",
    "locations = [DATA_LOCATION, DATA_LOCATION_INSIDER_RAW, DATA_LOCATION_INSIDER_PROCESSED, DATA_LOCATION_TIME_SERIES_RAW,\n",
    "             DATA_LOCATION_TIME_SERIES_PROCESSED, DATA_LOCATION_RI, DATA_LOCATION_MARKET, DATA_LOCATION_RI_interpolate, DATA_LOCATION_RI_discard]\n",
    "\n",
    "for loc in locations:\n",
    "    if not exists(loc):\n",
    "        os.makedirs(loc)\n",
    "\n",
    "# Period of interest\n",
    "end_time = datetime.datetime(2021, 12, 31, 23, 59, 59)\n",
    "end_time_unix = int(time.mktime(end_time.timetuple()))\n",
    "start_time = datetime.datetime(2018, 1, 1, 0, 0, 0)\n",
    "start_time_unix = int(time.mktime(start_time.timetuple()))\n",
    "download_type = ['P', 'S', 'A', 'D', 'G', 'F', 'M', 'X', 'C', 'W']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading tickers\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m data \u001B[38;5;241m=\u001B[39m URTI\u001B[38;5;241m.\u001B[39mread_tickers_and_isins(INPUT_FILE)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Download the dealings\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[43mUGDD\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_all_directors_dealings_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA_LOCATION_INSIDER_RAW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_date_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Cleanse the dealings\u001B[39;00m\n\u001B[0;32m     17\u001B[0m UPDD\u001B[38;5;241m.\u001B[39mpreprocess_directors_dealings(DATA_LOCATION_INSIDER_RAW, DATA_LOCATION_INSIDER_PROCESSED)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\InterdisciplinaryProject\\DD_Project\\source\\get_directors_dealings.py:79\u001B[0m, in \u001B[0;36mget_all_directors_dealings_async\u001B[1;34m(_data_location_insider_raw, _data, _download_type, to_date_name)\u001B[0m\n\u001B[0;32m     77\u001B[0m loop \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mget_event_loop()\n\u001B[0;32m     78\u001B[0m tasks \u001B[38;5;241m=\u001B[39m [loop\u001B[38;5;241m.\u001B[39mcreate_task(get_single_directors_dealings_async(\u001B[38;5;241m*\u001B[39mparamset)) \u001B[38;5;28;01mfor\u001B[39;00m paramset \u001B[38;5;129;01min\u001B[39;00m params]\n\u001B[1;32m---> 79\u001B[0m \u001B[43mloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_until_complete\u001B[49m\u001B[43m(\u001B[49m\u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m loop\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\.conda\\envs\\IDP\\lib\\asyncio\\base_events.py:592\u001B[0m, in \u001B[0;36mBaseEventLoop.run_until_complete\u001B[1;34m(self, future)\u001B[0m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;124;03m\"\"\"Run until the Future is done.\u001B[39;00m\n\u001B[0;32m    582\u001B[0m \n\u001B[0;32m    583\u001B[0m \u001B[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;124;03mReturn the Future's result, or raise its exception.\u001B[39;00m\n\u001B[0;32m    590\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[1;32m--> 592\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_running\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    594\u001B[0m new_task \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m futures\u001B[38;5;241m.\u001B[39misfuture(future)\n\u001B[0;32m    595\u001B[0m future \u001B[38;5;241m=\u001B[39m tasks\u001B[38;5;241m.\u001B[39mensure_future(future, loop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\IDP\\lib\\asyncio\\base_events.py:552\u001B[0m, in \u001B[0;36mBaseEventLoop._check_running\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    550\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_running\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    551\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_running():\n\u001B[1;32m--> 552\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis event loop is already running\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m events\u001B[38;5;241m.\u001B[39m_get_running_loop() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    554\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    555\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCannot run the event loop while another loop is running\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "if prepare_and_download:\n",
    "    # Download market data\n",
    "    start_time = datetime.datetime(2016, 3, 21, 0, 0, 0)\n",
    "    _start_time_unix = int(time.mktime(start_time.timetuple()))\n",
    "\n",
    "    end_time = datetime.datetime(2022, 3, 21, 23, 59, 59)\n",
    "    _end_time_unix = int(time.mktime(end_time.timetuple()))\n",
    "\n",
    "    ## download market_data\n",
    "    market_timeseries = UGMD.get_market_data(_ticker, _start_time_unix, _end_time_unix, DATA_LOCATION_MARKET)\n",
    "\n",
    "    # Read which companies should be analyzed\n",
    "    data = URTI.read_tickers_and_isins(INPUT_FILE)\n",
    "    # Download the dealings\n",
    "    UGDD.get_all_directors_dealings_async(DATA_LOCATION_INSIDER_RAW, data, download_type, to_date_name)\n",
    "    # Cleanse the dealings\n",
    "    UPDD.preprocess_directors_dealings(DATA_LOCATION_INSIDER_RAW, DATA_LOCATION_INSIDER_PROCESSED)\n",
    "    tickers, isins = data[\"TICKER SYMBOL\"], data[\"ISIN CODE\"]\n",
    "    # Preprocess raw data\n",
    "    ## Don't think this one is needed anymore:\n",
    "    UPTS.preprocess_timeseries(DATA_LOCATION_TIME_SERIES_RAW, DATA_LOCATION_TIME_SERIES_PROCESSED)\n",
    "\n",
    "    # Process the timeseries from Professor\n",
    "    ## Currently doing both methods - then we can change input dataset in the notebook.\n",
    "    processed_files = UPTFE.preprocess_timeseries_from_excel(INPUT_FILE, TIMESERIES_FILES, market_timeseries,\n",
    "                                                             DATA_LOCATION_RI_interpolate,\n",
    "                                                             DATA_LOCATION_INSIDER_PROCESSED, 'interpolate')\n",
    "    processed_files = UPTFE.preprocess_timeseries_from_excel(INPUT_FILE, TIMESERIES_FILES, market_timeseries,\n",
    "                                                             DATA_LOCATION_RI_discard, DATA_LOCATION_INSIDER_PROCESSED,\n",
    "                                                             'discard')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}