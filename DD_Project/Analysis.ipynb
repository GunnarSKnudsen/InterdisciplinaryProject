{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook for analyzing Insider tradings and the effects on stock prices\n",
    "Written by Thomas Niedermayer and Gunnar Sjúrðarson Knudsen, as a conjoined effort for an interdiscplinary project in Data Science.\n",
    "\n",
    "Supervisor: Wolfgang Aussenegg\n",
    "\n",
    "Co-Supervisor: Sascha Hunold\n",
    "\n",
    "Purpose of this notebook is XXX\n",
    "\n",
    "## Remaining todos:\n",
    "* Create README.md and add a diagram of the project\n",
    "* T1_ vs T1!!!\n",
    "* A lot!\n",
    "* Figure out which custom functions we are still using\n",
    "* Figure out if different hypotheses should be tested based on \"NAME\" - or do both do all analysis?\n",
    "* Refactor - we have data locations in two different varialbes (CAPS and preceeding underscore)\n",
    "* I MIGHT have deleted too much from data_checks.run\n",
    "* Currently have two different datasets for the ReturnIndex data - with (linear) interpolation, as well as skipping rows that don't exist in market and company.\n",
    "* Figure out what to do, when event date not in the dataset. Could still \"just\" do closest possible, provided that trades occur around the date.\n",
    "* What do we do when tickers are non-unique!? I think this is a nasty that breaks more than we know\n",
    "* document get_all_directors_dealings_async\n",
    "* Are outliers \"Significant\"? Wilcoxon compared to t-test\n",
    "\n",
    "#### Ask Prof. Aussenegg\n",
    "* How to compare before and after pandemic? subsample to get the same sample size and 2 sample ttest? -> for now, timebased aggregation\n",
    "* Is it fair to compare like before pandemic with during pandemic? when there is an estimation window in the pre pandemic time and the event window is in the pandemic time\n",
    "* Are we allowed to persist and upload the preprocessed data for this study?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hypotheses\n",
    "\n",
    "#### Gunnar\n",
    "\n",
    "1. Hypothesis 1: Insiders are able to earn significant abnormal returns in the first\n",
    "weeks after disclosure.\n",
    "2. Hypothesis 2: Trades of type “Purchase” are most explaining of abnormal return.\n",
    "“Sale” less so, and “Sale + Option” does not have an effect.\n",
    "3. Hypothesis 3: Directors have changed behaviour during the times of Covid.\n",
    "\n",
    "#### Tom\n",
    "\n",
    "1. Hypothesis 1: Insiders are able to earn significant abnormal returns in\n",
    "the first weeks after disclosure of relevant information.\n",
    "2. Hypothesis 2: Insiders are significantly good at avoiding risk indicated\n",
    "by market downturns after insiders selling shares.\n",
    "3. Hypothesis 3: Directors have changed behaviour during the times of\n",
    "covid: Hypotheses 1 and 2 can be answered with significantly different\n",
    "confidence before and during the pandemic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define which analysis is run\n",
    "Add a name here. This affects which data is read in, as well as which analysis are done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "NAME = \"Knudsen\"\n",
    "NAME = \"Niedermayer\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# custom functions\n",
    "import source.analyse_single_company as UASC\n",
    "from source import data_checks, determine_T0_T1_T2, cut_timeseries, calculate_coefficients\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "#plt.style.use(\"seaborn\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read in the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "         ISIN CODE                                 NAME TICKER SYMBOL  \\\n764   US35953D1046                               FUBOTV          FUBO   \n954   US46124J2015                INVENTRUST PROPERTIES           IVT   \n1939           NaN                         ABOVENET 'B'          ABVT   \n2093           NaN     ATHENA CONSUMER ACQUISITION CL B          ACAQ   \n2062           NaN       ARCTIC CAT 'B' DEAD - 07/03/17          ACAT   \n...            ...                                  ...           ...   \n1057  US53228T1016                    LIGHTNING EMOTORS           ZEV   \n3636  US98979J1097  ZOES KITCHEN DEAD - DELIST.21/11/18          ZOES   \n1923  US98978V1035                             ZOETIS A           ZTS   \n1926  US98983L1089                 ZURN WATER SOLUTIONS           ZWS   \n1927  CA98985W1023                      ZYMEWORKS (NYS)          ZYME   \n\n      trade_count  n_distinct_traders  n_distinct_trade_types  ts_rows  \\\n764            40                   8                       7   1509.0   \n954             4                   4                       1   1509.0   \n1939          179                  21                      10    824.0   \n2093            1                   1                       1    824.0   \n2062          446                  33                       8    824.0   \n...           ...                 ...                     ...      ...   \n1057           16                  13                       5    430.0   \n3636           87                  17                       8    675.0   \n1923          499                  34                       8   1509.0   \n1926          526                  27                       8   1509.0   \n1927           82                  10                       5   1230.0   \n\n           reason_to_exclude  \n764   Faulty timeseries data  \n954   Faulty timeseries data  \n1939            Missing ISIN  \n2093            Missing ISIN  \n2062            Missing ISIN  \n...                      ...  \n1057                    None  \n3636                    None  \n1923                    None  \n1926                    None  \n1927                    None  \n\n[3642 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ISIN CODE</th>\n      <th>NAME</th>\n      <th>TICKER SYMBOL</th>\n      <th>trade_count</th>\n      <th>n_distinct_traders</th>\n      <th>n_distinct_trade_types</th>\n      <th>ts_rows</th>\n      <th>reason_to_exclude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>764</th>\n      <td>US35953D1046</td>\n      <td>FUBOTV</td>\n      <td>FUBO</td>\n      <td>40</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1509.0</td>\n      <td>Faulty timeseries data</td>\n    </tr>\n    <tr>\n      <th>954</th>\n      <td>US46124J2015</td>\n      <td>INVENTRUST PROPERTIES</td>\n      <td>IVT</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1509.0</td>\n      <td>Faulty timeseries data</td>\n    </tr>\n    <tr>\n      <th>1939</th>\n      <td>NaN</td>\n      <td>ABOVENET 'B'</td>\n      <td>ABVT</td>\n      <td>179</td>\n      <td>21</td>\n      <td>10</td>\n      <td>824.0</td>\n      <td>Missing ISIN</td>\n    </tr>\n    <tr>\n      <th>2093</th>\n      <td>NaN</td>\n      <td>ATHENA CONSUMER ACQUISITION CL B</td>\n      <td>ACAQ</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>824.0</td>\n      <td>Missing ISIN</td>\n    </tr>\n    <tr>\n      <th>2062</th>\n      <td>NaN</td>\n      <td>ARCTIC CAT 'B' DEAD - 07/03/17</td>\n      <td>ACAT</td>\n      <td>446</td>\n      <td>33</td>\n      <td>8</td>\n      <td>824.0</td>\n      <td>Missing ISIN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1057</th>\n      <td>US53228T1016</td>\n      <td>LIGHTNING EMOTORS</td>\n      <td>ZEV</td>\n      <td>16</td>\n      <td>13</td>\n      <td>5</td>\n      <td>430.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3636</th>\n      <td>US98979J1097</td>\n      <td>ZOES KITCHEN DEAD - DELIST.21/11/18</td>\n      <td>ZOES</td>\n      <td>87</td>\n      <td>17</td>\n      <td>8</td>\n      <td>675.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1923</th>\n      <td>US98978V1035</td>\n      <td>ZOETIS A</td>\n      <td>ZTS</td>\n      <td>499</td>\n      <td>34</td>\n      <td>8</td>\n      <td>1509.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1926</th>\n      <td>US98983L1089</td>\n      <td>ZURN WATER SOLUTIONS</td>\n      <td>ZWS</td>\n      <td>526</td>\n      <td>27</td>\n      <td>8</td>\n      <td>1509.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1927</th>\n      <td>CA98985W1023</td>\n      <td>ZYMEWORKS (NYS)</td>\n      <td>ZYME</td>\n      <td>82</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1230.0</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>3642 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want to reduce to 1534 isins\n",
      "Found 2171 possible files to analyze\n",
      "We are left with 1534 to analyze\n",
      "loading return series...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 458/1534 [00:00<00:01, 672.41it/s]"
     ]
    }
   ],
   "source": [
    "# Data locations\n",
    "DATA_LOCATION = f'data/{NAME}/'\n",
    "DATA_LOCATION_INSIDER_PROCESSED = DATA_LOCATION + 'processed/insider/'\n",
    "DATA_LOCATION_RI = DATA_LOCATION + 'processed/RI_discard/'\n",
    "\n",
    "investigation_periods = {\n",
    "    \"overall\": (pd.Timestamp(\"2018-01-01\"), pd.Timestamp(\"2021-12-31\")),\n",
    "    \"pre-pandemic\": (pd.Timestamp(\"2018-01-01\"), pd.Timestamp(\"2020-02-29\")),\n",
    "    \"pandemic\": (pd.Timestamp(\"2020-03-01\"), pd.Timestamp(\"2021-12-31\")),\n",
    "}\n",
    "\n",
    "\n",
    "# Read in the summary data from \"CompaniesToExclude\" notebook\n",
    "summary_data = pd.read_csv(DATA_LOCATION + '/scraping_summary.csv', index_col=0)\n",
    "# Generate list of which companies to analyse\n",
    "isins_to_use = summary_data[summary_data['reason_to_exclude'] == 'None']['ISIN CODE'].to_list()\n",
    "display(summary_data)\n",
    "print(f'We want to reduce to {len(isins_to_use)} isins')\n",
    "\n",
    "# set plotting sizes\n",
    "tick_size = 15\n",
    "label_size = 20\n",
    "title_size = 30\n",
    "fig_height = 20\n",
    "\n",
    "## Not sure why we do this - maybe refactor\n",
    "_ri_location = DATA_LOCATION_RI\n",
    "_insider_location = DATA_LOCATION_INSIDER_PROCESSED\n",
    "\n",
    "# Get locations to read in\n",
    "file_locs_ = os.listdir(_ri_location)\n",
    "print(f'Found {len(file_locs_)} possible files to analyze')\n",
    "# Filter files for analysis, and append path:\n",
    "file_locs = [_ri_location + f for f in file_locs_ if f[:-7] in isins_to_use]\n",
    "print(f'We are left with {len(file_locs)} to analyze')\n",
    "\n",
    "# Actually read in the company information\n",
    "companies = []\n",
    "print(\"loading return series...\")\n",
    "for file_loc in tqdm(file_locs):\n",
    "    with open(file_loc, \"rb\") as f:\n",
    "        company = pickle.load(f)\n",
    "    companies.append(company)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate Returns, Analyse Companies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Returns\")\n",
    "returns_df = [c.return_index_df.company_return for c in companies]\n",
    "\n",
    "print(\"concatenate\")\n",
    "df_returns = pd.concat(returns_df, axis=1)\n",
    "df_return_index = pd.concat([c.return_index_df for c in companies], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise Mean Daily Returns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick')\n",
    "plt.rc('ytick')\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "returns_companies = df_returns.mean(axis=1)\n",
    "returns_companies.plot(color=\"k\", linewidth=0.7)\n",
    "\n",
    "ax.set_xlabel('Time (Years)', fontsize=label_size)\n",
    "ax.set_ylabel('Mean Daily Return', fontsize=label_size)\n",
    "ax.set_title('Mean Daily Returns Over Time', fontsize=title_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "interval_borders = [\"2018-01-01\", \"2020-03-01\", \"2021-12-31\"] # TODO see if it makes sense to actually take first of Feb\n",
    "\n",
    "for int_ in interval_borders:\n",
    "    plt.axvline(x = int_, color = 'red', label = 'DD Event time', linewidth = 1)\n",
    "\n",
    "plt.savefig(DATA_LOCATION +\"visualisations/NYSE_daily_returns.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "# get var for the intervals\n",
    "print(\"variance of the intervals\")\n",
    "print(f'{round(returns_companies.loc[\"2018-01-01\":\"2020-02-29\"].var(),10):.20f}')\n",
    "print(f'{round(returns_companies.loc[\"2020-03-01\":\"2021-12-31\"].var(), 10):.20f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove companies outside of the timeframe of interest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this is the interval where filings are interesting to us\n",
    "earliest_timestamp = list(investigation_periods.values())[0][0]\n",
    "latest_timestamp = list(investigation_periods.values())[-1][1]\n",
    "filings_removed = 0\n",
    "filings_total = 0\n",
    "\n",
    "for company in tqdm(companies):\n",
    "    insider_data_df = company.insider_data_df\n",
    "    filing_dates = insider_data_df.FilingDate.apply(lambda x: x.floor(\"d\"))\n",
    "    mask = (filing_dates >= earliest_timestamp) & (filing_dates <= latest_timestamp)\n",
    "    company.insider_data_df = company.insider_data_df[mask]\n",
    "    filings_removed += (~mask).sum()\n",
    "    filings_total += mask.shape[0]\n",
    "\n",
    "print(\"Total filings: {}\".format(filings_total))\n",
    "print(\"Removed {} filings\".format(filings_removed))\n",
    "print(\"Remaining filings: {}\".format(filings_total - filings_removed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Investigate Filing Trade Lag Times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"get filing lags ...\")\n",
    "\n",
    "lags = []\n",
    "for company in tqdm(companies):\n",
    "    lag = UASC.analyse_single_company(company)\n",
    "    lags.append(lag)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filing_trade_lags = sum(lags, [])\n",
    "\n",
    "lag_in_hours = np.asarray(filing_trade_lags)\n",
    "negative_lag_mask = lag_in_hours < 0\n",
    "positive_lag = lag_in_hours[~negative_lag_mask]\n",
    "in_21_days = positive_lag < 21*24\n",
    "relevant_lag = positive_lag[in_21_days]\n",
    "print(f\"Negative lag for {negative_lag_mask.sum()} out of {len(negative_lag_mask)} trades.\")\n",
    "print(f\"Lag longer than 21 days for {len(positive_lag) - len(relevant_lag)} out of {len(negative_lag_mask)} trades.\")\n",
    "print(f\"Eligible trades: {len(relevant_lag)} out of {len(negative_lag_mask)} trades.\")\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.hist(np.log(positive_lag), bins=\"auto\")\n",
    "ax.set_xlabel('Time (Log(Hours))', fontsize=label_size)\n",
    "ax.set_ylabel('Trades', fontsize=label_size)\n",
    "ax.set_title('Distribution of Log Lag Times between Filing and Trade', fontsize=title_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.axvline(x = 0, color = 'red', label = 'Zero', linewidth = 3)\n",
    "plt.axvline(x = np.log(21*24), color = 'red', label = 'Threshold', linewidth = 3)\n",
    "plt.savefig(DATA_LOCATION +\"visualisations/log_transformed_lags.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "without_outliers = positive_lag[positive_lag < 24*21]\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.hist(without_outliers, bins=\"auto\")\n",
    "plt.xticks(np.arange(0, max(without_outliers) + 1, 24))\n",
    "ax.set_xlabel('Time (Hours)', fontsize=label_size)\n",
    "ax.set_ylabel('Trades', fontsize=label_size)\n",
    "ax.set_title('Distribution of Lag Times between Filing and Trade', fontsize=title_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.savefig(DATA_LOCATION +\"visualisations/lags_without_outliers.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop companies with lags longer than 21 days or negative lags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for lags_c, company in tqdm(zip(lags, companies)):\n",
    "    lags_c = np.asarray(lags_c)\n",
    "    mask_eligible = (lags_c >= 0) | (lags_c <= 21*24)\n",
    "    company.insider_data_df = company.insider_data_df[mask_eligible]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demonstrate process for a single event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define windows\n",
    "\n",
    "#### Our data contains multiple companies. A single company contains multiple filings and each filing is an event\n",
    "\n",
    "![alt text](assets/images/windows.png \"Title\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Constants defining how long both Estimation Window and Event Window are\n",
    "### Probably also input parameters to a function call, as we need loops later...\n",
    "L1_length = 100\n",
    "L2_length = 40 # TODO +-20 days = 40 days, right?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fix a company"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "if NAME == \"Knudsen\":\n",
    "    company_index = -87\n",
    "elif NAME == \"Niedermayer\":\n",
    "    company_index = -11\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "company = companies[company_index]\n",
    "print(company)\n",
    "company_return = company.return_index_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fix an event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This date will be moved to a loop\n",
    "## Define which periods we are looking at.\n",
    "\n",
    "if NAME == \"Knudsen\":\n",
    "    event_index = 60\n",
    "elif NAME == \"Niedermayer\":\n",
    "    event_index = -200\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "event_timestamp = company.insider_data_df.FilingDate.iloc[event_index].floor(\"d\")\n",
    "print(\"event timestamp: \", event_timestamp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Technical Checks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_checks.run(L1_length, L2_length, event_timestamp, company_return)#, market_timeseries)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#company_return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Determine T0, T1 and T2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T0_, T1_, T2_, T0, T1, T2, ERROR, msg = determine_T0_T1_T2.run(L1_length, L2_length, event_timestamp, company_return)#, market_timeseries)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(event_timestamp)\n",
    "company_return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Abnormal and Normal Returns\n",
    "\n",
    "![alt text](assets/images/return_estimation.png \"Title\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cut return timeseries into correct periods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "windows = cut_timeseries.run(company_return, T0, T1, T2)\n",
    "estimation_window_market_return, estimation_window_company_return, event_window_market_return, event_window_company_return = windows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate coefficients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha, beta = calculate_coefficients.run(estimation_window_market_return, estimation_window_company_return)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Abnormal Return\n",
    "This is the last step of the whole process for one event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "company_return = event_window_company_return\n",
    "market_return = event_window_market_return\n",
    "estimated_return = alpha + beta*market_return\n",
    "abnormal_return = company_return - estimated_return\n",
    "print(abnormal_return)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "company_and_estimated = pd.DataFrame({\"company\":event_window_company_return, \"market\":estimated_return})\n",
    "company_and_market = pd.DataFrame({\"company\": estimation_window_company_return, \"market\":estimation_window_market_return})\n",
    "df_to_plot = pd.concat([company_and_market, company_and_estimated])\n",
    "df_to_plot.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Company_name = company.name\n",
    "\n",
    "# Estimations\n",
    "est_estimation = estimation_window_market_return * beta + alpha\n",
    "est_event = event_window_market_return * beta + alpha\n",
    "\n",
    "plt.figure(figsize=(fig_height,10))\n",
    "estimation_window_market_return.plot(color = 'black', alpha = 0.6, linewidth=4, label = 'Market Return (Estimation Window)')\n",
    "event_window_market_return.plot(color = 'black', alpha = 0.9, linewidth=4, label = 'Market Return (Event Window)')\n",
    "\n",
    "estimation_window_company_return.plot(color = 'blue', alpha = 0.6, linewidth = 4, label = f'{Company_name} Return (Estimation Window)')\n",
    "event_window_company_return.plot(color = 'blue', alpha = 0.9, linewidth = 4, label = f'{Company_name} Return (Event Window)')\n",
    "\n",
    "plt.axvline(x = event_timestamp, color = 'red', label = 'DD Event time', linewidth = 5)\n",
    "plt.ylabel(f'Daily Returns', fontsize=label_size)\n",
    "est_estimation.plot(color = 'green', label = f'Regression Estimate for {Company_name}', alpha = 0.8)\n",
    "est_event.plot(color = 'green', label = f'Regression Estimate for {Company_name}', alpha = 1)\n",
    "\n",
    "plt.axvspan(T0, T1, ymin = 0.05, ymax = 0.95, facecolor='black', alpha=0.1, label = 'Estimation Window', edgecolor='g', linewidth=5)\n",
    "plt.axvspan(T1, T2, ymin = 0.05, ymax = 0.95, facecolor='black', alpha=0.2, label = 'Event Window', edgecolor='r', linewidth=5)\n",
    "plt.legend(bbox_to_anchor = (1.0, 1), loc = 'upper left')\n",
    "\n",
    "plt.title(f'Show how company \"{Company_name}\" moves around the event, compared to the market', fontsize = title_size)\n",
    "plt.xlabel('Date', fontsize=label_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.show()\n",
    "print(\"I'm impressed! It looks like a five-year-old drew this plot in paint\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EVENT_INDEX = 20 # because 20 [0,..19] are before the event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Macro Analysis\n",
    "\n",
    "### Now that we have seen the process for one single filing, let us do the same for all filings in all companies\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize testing\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# Helpers\n",
    "multiind, data, data_errors = [], [], []\n",
    "n_companies = len(companies)\n",
    "\n",
    "\n",
    "#for j in tqdm(range(len(companies[:200]))):\n",
    "for j in tqdm(range(len(companies))):\n",
    "    # Get information from said company\n",
    "    company = companies[j]\n",
    "    company_return = company.return_index_df\n",
    "    \n",
    "    n_filings = len(company.insider_data_df)\n",
    "    # Go through all filings\n",
    "    for i in company.insider_data_df.FilingDate.index:\n",
    "\n",
    "        # TODO probably not used anymore\n",
    "        # Find our event date from filing\n",
    "        filing_date = company.insider_data_df.FilingDate[i]\n",
    "        event_timestamp = filing_date.floor(\"d\")\n",
    "\n",
    "        # TODO probably not used anymore\n",
    "        # if the timestamp is too early or too late we skip\n",
    "        if event_timestamp < earliest_timestamp or event_timestamp > latest_timestamp:\n",
    "            #print(\"skipping, filing is too early or too late\")\n",
    "            continue\n",
    "            \n",
    "        #print(f\"working on company {j}/{n_companies} named {company.name}, filing {i}/{n_filings}\")\n",
    "\n",
    "        # do the process for one filing\n",
    "        ## See if it's possible\n",
    "        checks = data_checks.run(L1_length, L2_length, event_timestamp, company_return)\n",
    "        if checks:\n",
    "            #print(checks[1])\n",
    "            data_errors.append(checks[0])\n",
    "            continue\n",
    "   \n",
    "        ## Proceed to find periods\n",
    "        T0_, T1_, T2_, T0, T1, T2, ERRORS, msg = determine_T0_T1_T2.run(L1_length, L2_length, event_timestamp, company_return)\n",
    "        if ERRORS:\n",
    "            #print(msg)\n",
    "            data_errors.append(ERRORS)\n",
    "            continue\n",
    "            \n",
    "        ## Cut timeseries to the relevant periods, and split them\n",
    "        windows = cut_timeseries.run(company_return, T0, T1, T2)\n",
    "        estimation_window_market_return, estimation_window_company_return, event_window_market_return, event_window_company_return = windows\n",
    "        alpha, beta = calculate_coefficients.run(estimation_window_market_return, estimation_window_company_return)\n",
    "\n",
    "        ## Calculate the abnormal returns\n",
    "        abnormal_return = event_window_company_return - alpha - beta*event_window_market_return\n",
    "        \n",
    "        ## Append to results set\n",
    "        multiind.append((company.ticker, i, company.insider_data_df.TradeType[i], event_timestamp))\n",
    "        data.append(abnormal_return)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# process abnormal returns\n",
    "df_abnormal_returns = pd.DataFrame.from_records([d.reset_index(drop=True) for d in data])\n",
    "df_abnormal_returns.index = pd.MultiIndex.from_tuples(multiind, names=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"])\n",
    "df_abnormal_returns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_abnormal_returns.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show the reasons filings were dropped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "errors_df = pd.DataFrame.from_records(data_errors)\n",
    "errors_df.sum(axis=0).plot.bar()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Having a look at all trade types together"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "types_of_interest = [\"P - Purchase\", \"S - Sale\", \"S - Sale+OE\"]\n",
    "df_abnormal_returns.loc[:,:,types_of_interest,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "a = df_abnormal_returns.loc[:,:,types_of_interest,:].groupby(level=[2]).mean().transpose().plot(figsize=(fig_height, 10))\n",
    "plt.plot(np.zeros(len(df_abnormal_returns.columns)), color=\"black\", linewidth=0.5)\n",
    "a.set_title(\"Abnormal Returns of selected Trade Types\",fontsize=title_size)\n",
    "a.set_xlabel(\"Days\", fontsize=label_size)\n",
    "a.set_ylabel(\"Mean Abnormal Return\", fontsize=label_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.axvline(x = EVENT_INDEX, color = 'red', label = 'DD Event time', linewidth = 1.5)\n",
    "plt.savefig(f\"data/{NAME}/visualisations/AR_selected_tradetypes.png\", dpi=600, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = df_abnormal_returns.groupby(level=[2]).mean().transpose().plot(figsize=(fig_height, 10), fontsize=15)\n",
    "plt.plot(np.zeros(len(df_abnormal_returns.columns)), color=\"black\", linewidth=0.5)\n",
    "a.set_title(\"Abnormal Returns of all Trade Types\",fontsize=title_size)\n",
    "a.set_xlabel(\"Days\", fontsize=label_size)\n",
    "a.set_ylabel(\"mean Abnormal Return\", fontsize=label_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.axvline(x = EVENT_INDEX, color = 'red', label = 'DD Event time', linewidth = 1.5)\n",
    "plt.savefig(f\"data/{NAME}/visualisations/AR_all_tradetypes.png\", dpi=600, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_abnormal_returns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I think OE and OptEx means option exercise. \"to exercise\" means to put into effect the right to buy or sell the underlying security that is specified in the options contract.\" Can we be sure that the action does not shift the market, and the swing in return is really due to new information? Are these trades public, so maybe they are used as a signal for traders?\n",
    "\n",
    "### Boxplot of the sum over all companies's AR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![alt text](assets/images/time_agg.png)\n",
    "\n",
    "In our case it is not company i, but filing i\n",
    "\n",
    "Types of trade to pick from:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = df_abnormal_returns.groupby(level=[2]).sum().transpose().plot.box(rot=90, figsize=(fig_height, 10))\n",
    "ax.set_title(\"Boxplots of the Abnormal Returns for each Trade Type\",fontsize=title_size)\n",
    "ax.set_xlabel(\"Trade Type\", fontsize=label_size)\n",
    "ax.set_ylabel(\"Abnormal Return\", fontsize=label_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.savefig(f\"data/{NAME}/visualisations/AR_all_tradetypes_boxplot.png\", dpi=600, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "types = list(set([x[2] for x in df_abnormal_returns.index]))\n",
    "types"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Specify the type of the trades to investigate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type_ = \"P - Purchase\" # \"S - Sale\"\n",
    "df_abnormal_returns_type = df_abnormal_returns.loc[:,:,type_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The index describes the company and the index of the filing in the compnay, the columns represent the days in the event window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_abnormal_returns_type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO Infinity Values idk why, should check out why they are there upstream"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask = (-df_abnormal_returns_type == np.Inf) |(df_abnormal_returns_type == np.Inf)\n",
    "print(mask.sum().sum())\n",
    "df_abnormal_returns_type[mask] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CAR = df_abnormal_returns_type.sum(axis=1)\n",
    "CAR.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![alt text](assets/images/cross_sectional_agg.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AR_bar = df_abnormal_returns_type.mean(axis=0) \n",
    "AR_bar.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CAR_bar = AR_bar.sum()\n",
    "CAR_bar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO var_CAR_bar = Does the definition make sense? It seems like we take the var of a scalar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![alt text](assets/images/cross_sectional_agg2.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CAR_bar_2 = CAR.mean()\n",
    "CAR_bar_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# var car TODO not sure what just sigma means."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Statistics\n",
    "\n",
    "Check if CAR mean = 0 (t-test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "tt = stats.ttest_1samp(CAR, popmean=0)\n",
    "tt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if CAR median = 0 (wilcoxon signed rank test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats.wilcoxon(CAR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "types = types\n",
    "investigation_periods = investigation_periods\n",
    "multiind_p, data_p = [], []\n",
    "\n",
    "event_day_ranges = {\n",
    "    \"before\": (0,20), # TODO for now we drop the filing day itself\n",
    "    \"after\": (21,41)\n",
    "}\n",
    "\n",
    "\n",
    "for type_ in types:\n",
    "    for per in investigation_periods.keys():\n",
    "        for side in event_day_ranges.keys():\n",
    "                \n",
    "            event_day_range = event_day_ranges[side]\n",
    "            df_abnormal_returns_type = df_abnormal_returns.loc[:,:,type_]\n",
    "            per_left, per_right = investigation_periods[per]\n",
    "\n",
    "\n",
    "            timestamps = df_abnormal_returns_type.index.get_level_values(2)\n",
    "            mask = (timestamps >= per_left) & (timestamps <= per_right)\n",
    "            df_AR_type_per = df_abnormal_returns_type[mask]\n",
    "            if not len(df_AR_type_per):\n",
    "                print(f\"skipping iteration because of 0 datapoints {(type_, per, side)}\")\n",
    "                continue\n",
    "            df_AR_type_per_side = df_AR_type_per.iloc[:,event_day_range[0]:event_day_range[1]]\n",
    "            CAR = df_AR_type_per_side.sum(axis=1)\n",
    "\n",
    "            pvalue_ttest = round(stats.ttest_1samp(CAR, popmean=0).pvalue, 10)\n",
    "            pvalue_wilcoxon = round(stats.wilcoxon(CAR).pvalue, 10)\n",
    "            mean = CAR.mean()\n",
    "            median = CAR.median()\n",
    "            # calculate a 95% confidence interval\n",
    "            left, right = stats.t.interval(0.95, len(CAR)-1, loc=np.mean(CAR), scale=stats.sem(CAR))\n",
    "            left, right = round(left, 4), round(right, 4)\n",
    "            CI = left, right\n",
    "            \n",
    "            multiind_p.append((type_, per, side))\n",
    "            data_p.append((mean, pvalue_ttest, median, pvalue_wilcoxon, len(df_AR_type_per), CI))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# process abnormal returns\n",
    "df_p = pd.DataFrame.from_records(data_p)\n",
    "df_p.index = pd.MultiIndex.from_tuples(multiind_p, names=[\"TradeType\", \"Period\", \"Side\"])\n",
    "df_p.columns = [\"mean\", \"ttest pvalue\", \"median\", \"wilcoxon pvalue\", \"sample_size\", \"95% CI\"]\n",
    "df_p.to_csv(f\"data/{NAME}/tests_result.csv\")\n",
    "df_p.sort_values(\"ttest pvalue\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_p.loc[\"S - Sale\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Export information to latex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for t in types:\n",
    "    counter = counter+1\n",
    "    #print(t)\n",
    "    df_ = df_p.loc[t,:,:]\n",
    "    df_ = df_.rename(columns={'Side of the event': 'Side'\n",
    "                              , 'mean': 'mean'\n",
    "                              , 'ttest pvalue': 'ttest'\n",
    "                              , 'median': 'median'\n",
    "                              , 'wilcoxon pvalue': 'Wilcoxon'\n",
    "                              , 'sample_size': 'N'})\n",
    "    #display(df_)\n",
    "    \n",
    "    latex = df_.drop(columns=[\"95% CI\"])\\\n",
    "    .to_latex( column_format=\"llrrrrr\"\n",
    "              , position=\"H\"\n",
    "              , label=f\"table:t{counter}_hypothesistest\"\n",
    "              , caption= f\"Hypothesis tests for type: {t}\"\n",
    "              #, index = False\n",
    "    )\n",
    "    print(latex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise CI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time based aggregation\n",
    "\n",
    "In order to compare pre-pandemic and pandemic time, we cannot do cross sectional aggregation because then we cannot carry out hypothesis tests. Therefore we aggregate the data in time and do a 2 sample t test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# purcase, sale and sale with oe\n",
    "for t in types_of_interest:\n",
    "    for side in event_day_ranges.keys():\n",
    "\n",
    "        df_ = df_p.loc[t,:,side]\n",
    "\n",
    "        def plot_confidence_interval(x, mean, CI, color='#2187bb', horizontal_line_width=0.25):\n",
    "\n",
    "\n",
    "            left = x - horizontal_line_width / 2\n",
    "            top = mean - CI\n",
    "            right = x + horizontal_line_width / 2\n",
    "            bottom = mean + CI\n",
    "            plt.plot([x, x], [top, bottom], color=color)\n",
    "            plt.plot([left, right], [top, top], color=color)\n",
    "            plt.plot([left, right], [bottom, bottom], color=color)\n",
    "            plt.plot(x, mean, 'o', color='#f44336')\n",
    "\n",
    "            return mean, CI\n",
    "\n",
    "        plt.figure(figsize=(fig_height,4))\n",
    "\n",
    "        df_to_plot = df_\n",
    "        for i, row in enumerate(df_to_plot.sort_values(\"mean\").itertuples()):\n",
    "            mean, CI = plot_confidence_interval(i, row[1], row[6][1] - row[1])\n",
    "\n",
    "        plt.plot(np.zeros(len(df_to_plot)), color=\"black\", linewidth=0.5)\n",
    "        plt.xticks(range(len(df_to_plot)), df_to_plot.index, fontsize=tick_size)\n",
    "        plt.yticks(fontsize=tick_size)\n",
    "\n",
    "        if side == \"before\":\n",
    "            side_desc = \"before the event\"\n",
    "        else:\n",
    "            side_desc = \"after the event\"\n",
    "\n",
    "        plt.title(f'CI of trade type  {t} | Abnormal return data {side_desc}', fontsize=title_size)\n",
    "\n",
    "        plt.xlabel('Time Frame', fontsize=label_size)\n",
    "        plt.ylabel('Mean Abnormal Return', fontsize=label_size)\n",
    "\n",
    "        plt.xticks(fontsize=tick_size)\n",
    "        plt.yticks(fontsize=tick_size)\n",
    "        plt.savefig(f\"data/{NAME}/visualisations/CI_{t}_{side}.png\", dpi=600, bbox_inches='tight')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_aggregated = df_abnormal_returns.sum(axis=1)#.transpose()\n",
    "matrix_data = dict()\n",
    "\n",
    "for side in event_day_ranges.keys():\n",
    "    d = {}\n",
    "    for t in types_of_interest:\n",
    "\n",
    "        event_day_range = event_day_ranges[side]\n",
    "        df_abnormal_returns_type = df_abnormal_returns.loc[:,:,t]\n",
    "\n",
    "        timestamps = df_abnormal_returns_type.index.get_level_values(2)\n",
    "\n",
    "        df_AR_type_side = df_abnormal_returns_type.iloc[:,event_day_range[0]:event_day_range[1]]\n",
    "\n",
    "\n",
    "        pand_start, pand_end = investigation_periods[\"pandemic\"][0], investigation_periods[\"pandemic\"][1]\n",
    "        prepand_start, prepand_end = investigation_periods[\"pre-pandemic\"][0], investigation_periods[\"pre-pandemic\"][1]\n",
    "\n",
    "        mask_pand = (timestamps >= pand_start) & (timestamps <= pand_end)\n",
    "        mask_prepand = (timestamps >= prepand_start) & (timestamps <= prepand_end)\n",
    "\n",
    "\n",
    "        df_AR_type_side_pand_agg = df_AR_type_side[mask_pand].mean(axis=0)\n",
    "        df_AR_type_side_prepand_agg = df_AR_type_side[mask_prepand].mean(axis=0)\n",
    "        plt.hist(df_AR_type_side_pand_agg)\n",
    "        plt.hist(df_AR_type_side_prepand_agg)\n",
    "        plt.show()\n",
    "\n",
    "        tt = stats.ttest_ind(a=df_AR_type_side_prepand_agg, b=df_AR_type_side_pand_agg)\n",
    "        print(f\"For type {t}, in the days {side} of the event, the pre-pandemic and pandemic mean of abnormal returns is different with a p-value of {round(tt.pvalue, 10)}\")\n",
    "\n",
    "        d.update({t:tt.pvalue})\n",
    "\n",
    "    matrix_data[side] = d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### P-values of whether pre-pandemic and pandemic are significantly different for the timeframe before and after the event and different types"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(matrix_data).to_latex())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Specify the type of the trades to investigate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Visualize how active Directors Dealings Are\n",
    "Should move this to somewhere else\n",
    "Want visual confirmation that Directors have changed behaviour during the times of Covid (Hypothesis 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_insider_trades = companies[0].insider_data_df.head(0)\n",
    "\n",
    "#for j in tqdm(range(len(companies[:200]))):\n",
    "for j in tqdm(range(len(companies))):\n",
    "    all_insider_trades = pd.concat([all_insider_trades, companies[j].insider_data_df])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_insider_trades['FilingDateTrunc'] = all_insider_trades['FilingDate'].dt.date\n",
    "all_insider_trades.groupby('FilingDateTrunc')['FilingDate'].count().plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_insider_trades.to_csv('AllTradesForExcelGSK.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_insider_trades.groupby('FilingDateTrunc')['Value'].sum().plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_insider_trades.groupby('FilingDateTrunc')['Value'].mean().plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(all_insider_trades['FilingDateTrunc'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick')\n",
    "plt.rc('ytick')\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "returns_companies = df_returns.mean(axis=1)\n",
    "returns_companies.plot(color=\"k\", linewidth=0.7)\n",
    "\n",
    "ax.set_xlabel('Time (Years)', fontsize=label_size)\n",
    "ax.set_ylabel('Mean Daily Return', fontsize=label_size)\n",
    "ax.set_title('Mean Daily Returns Over Time', fontsize=title_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "interval_borders = [\"2018-01-01\", \"2020-03-01\", \"2021-12-31\"] # TODO see if it makes sense to actually take first of Feb\n",
    "\n",
    "for int_ in interval_borders:\n",
    "    plt.axvline(x = int_, color = 'red', label = 'DD Event time', linewidth = 1)\n",
    "\n",
    "#plt.savefig(DATA_LOCATION +\"visualisations/NYSE_daily_returns.png\", dpi=600)\n",
    "plt.show()\n",
    "# get var for the intervals\n",
    "print(\"variance of the intervals\")\n",
    "print(f'{round(returns_companies.loc[\"2018-01-01\":\"2020-02-29\"].var(),10):.20f}')\n",
    "print(f'{round(returns_companies.loc[\"2020-03-01\":\"2021-12-31\"].var(), 10):.20f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades['FilingDateTrunc'] = all_insider_trades['FilingDate'].dt.date\n",
    "all_insider_trades.groupby('FilingDateTrunc')['FilingDate'].count().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades.to_csv('AllTradesForExcelGSK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades.groupby('FilingDateTrunc')['Value'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades.groupby('FilingDateTrunc')['Value'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(all_insider_trades['FilingDateTrunc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick')\n",
    "plt.rc('ytick')\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "returns_companies = df_returns.mean(axis=1)\n",
    "returns_companies.plot(color=\"k\", linewidth=0.7)\n",
    "\n",
    "ax.set_xlabel('Time (Years)', fontsize=label_size)\n",
    "ax.set_ylabel('Mean Daily Return', fontsize=label_size)\n",
    "ax.set_title('Mean Daily Returns Over Time', fontsize=title_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "interval_borders = [\"2018-01-01\", \"2020-03-01\", \"2021-12-31\"] # TODO see if it makes sense to actually take first of Feb\n",
    "\n",
    "for int_ in interval_borders:\n",
    "    plt.axvline(x = int_, color = 'red', label = 'DD Event time', linewidth = 1)\n",
    "\n",
    "#plt.savefig(DATA_LOCATION +\"visualisations/NYSE_daily_returns.png\", dpi=600)\n",
    "plt.show()\n",
    "# get var for the intervals\n",
    "print(\"variance of the intervals\")\n",
    "print(f'{round(returns_companies.loc[\"2018-01-01\":\"2020-02-29\"].var(),10):.20f}')\n",
    "print(f'{round(returns_companies.loc[\"2020-03-01\":\"2021-12-31\"].var(), 10):.20f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}