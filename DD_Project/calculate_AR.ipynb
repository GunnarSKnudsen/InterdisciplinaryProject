{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook for analyzing Insider tradings and the effects on stock prices\n",
    "Written by Thomas Niedermayer and Gunnar Sjúrðarson Knudsen, as a conjoined effort for an interdiscplinary project in Data Science.\n",
    "\n",
    "Supervisor: Wolfgang Aussenegg\n",
    "\n",
    "Co-Supervisor: Sascha Hunold\n",
    "\n",
    "Purpose of this notebook is XXX\n",
    "\n",
    "## Remaining todos:\n",
    "* Create README.md and add a diagram of the project\n",
    "* T1_ vs T1!!!\n",
    "* A lot!\n",
    "* Figure out which custom functions we are still using\n",
    "* Figure out if different hypotheses should be tested based on \"NAME\" - or do both do all analysis?\n",
    "* Refactor - we have data locations in two different varialbes (CAPS and preceeding underscore)\n",
    "* I MIGHT have deleted too much from data_checks.run\n",
    "* Currently have two different datasets for the ReturnIndex data - with (linear) interpolation, as well as skipping rows that don't exist in market and company.\n",
    "* Figure out what to do, when event date not in the dataset. Could still \"just\" do closest possible, provided that trades occur around the date.\n",
    "* What do we do when tickers are non-unique!? I think this is a nasty that breaks more than we know\n",
    "* document get_all_directors_dealings_async\n",
    "* Are outliers \"Significant\"? Wilcoxon compared to t-test\n",
    "\n",
    "#### Ask Prof. Aussenegg\n",
    "* Is it fair to compare like before pandemic with during pandemic? when there is an estimation window in the pre pandemic time and the event window is in the pandemic time\n",
    "* Are we allowed to persist and upload the preprocessed data for this study?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hypotheses\n",
    "\n",
    "#### Gunnar\n",
    "\n",
    "1. Hypothesis 1: Insiders are able to earn significant abnormal returns in the first\n",
    "weeks after disclosure.\n",
    "2. Hypothesis 2: Trades of type “Purchase” are most explaining of abnormal return.\n",
    "“Sale” less so, and “Sale + Option” does not have an effect.\n",
    "3. Hypothesis 3: Directors have changed behaviour during the times of Covid.\n",
    "\n",
    "#### Tom\n",
    "\n",
    "1. Hypothesis 1: Insiders are able to earn significant abnormal returns in\n",
    "the first weeks after disclosure of relevant information.\n",
    "2. Hypothesis 2: Insiders are significantly good at avoiding risk indicated\n",
    "by market downturns after insiders selling shares.\n",
    "3. Hypothesis 3: Directors have changed behaviour during the times of\n",
    "covid: Hypotheses 1 and 2 can be answered with significantly different\n",
    "confidence before and during the pandemic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define which analysis is run\n",
    "Add a name here. This affects which data is read in, as well as which analysis are done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "NAME = \"Knudsen\"\n",
    "#NAME = \"Niedermayer\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m stats\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# custom functions\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msource\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01manalyse_single_company\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mUASC\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\IDP\\lib\\site-packages\\scipy\\stats\\__init__.py:453\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m.. _statsrefmanual:\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    450\u001B[0m \n\u001B[0;32m    451\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 453\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stats_py\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_variation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m variation\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\IDP\\lib\\site-packages\\scipy\\stats\\_stats_py.py:39\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NumpyVersion\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspatial\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistance\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cdist\n\u001B[1;32m---> 39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mndimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _measurements\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_lib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_util\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (check_random_state, MapWrapper,\n\u001B[0;32m     41\u001B[0m                               rng_integers, float_factorial)\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecial\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mspecial\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\IDP\\lib\\site-packages\\scipy\\ndimage\\__init__.py:154\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_fourier\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401 F403\u001B[39;00m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_interpolation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401 F403\u001B[39;00m\n\u001B[1;32m--> 154\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_measurements\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401 F403\u001B[39;00m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_morphology\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401 F403\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001B[39;00m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:991\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:975\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:671\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:844\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:933\u001B[0m, in \u001B[0;36mget_code\u001B[1;34m(self, fullname)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1077\u001B[0m, in \u001B[0;36mpath_stats\u001B[1;34m(self, path)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:142\u001B[0m, in \u001B[0;36m_path_stat\u001B[1;34m(path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# custom functions\n",
    "import source.analyse_single_company as UASC\n",
    "from source import data_checks, determine_T0_T1_T2, cut_timeseries, calculate_coefficients\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "#plt.style.use(\"seaborn\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read in the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data locations\n",
    "DATA_LOCATION = f'data/{NAME}/'\n",
    "DATA_LOCATION_INSIDER_PROCESSED = DATA_LOCATION + 'processed/insider/'\n",
    "DATA_LOCATION_RI = DATA_LOCATION + 'processed/RI_discard/'\n",
    "\n",
    "# set plotting sizes\n",
    "tick_size = 15\n",
    "label_size = 20\n",
    "title_size = 30\n",
    "fig_height = 20\n",
    "\n",
    "investigation_periods = {\n",
    "    \"overall\": (pd.Timestamp(\"2018-01-01\"), pd.Timestamp(\"2021-12-31\")),\n",
    "    \"pre-pandemic\": (pd.Timestamp(\"2018-01-01\"), pd.Timestamp(\"2020-02-29\")),\n",
    "    \"pandemic\": (pd.Timestamp(\"2020-03-01\"), pd.Timestamp(\"2021-12-31\")),\n",
    "}\n",
    "\n",
    "# Read in the summary data from \"CompaniesToExclude\" notebook\n",
    "summary_data = pd.read_csv(DATA_LOCATION + '/scraping_summary.csv', index_col=0)\n",
    "# Generate list of which companies to analyse\n",
    "isins_to_use = summary_data[summary_data['reason_to_exclude'] == 'None']['ISIN CODE'].to_list()\n",
    "display(summary_data)\n",
    "print(f'We want to reduce to {len(isins_to_use)} isins')\n",
    "\n",
    "\n",
    "## Not sure why we do this - maybe refactor\n",
    "_ri_location = DATA_LOCATION_RI\n",
    "_insider_location = DATA_LOCATION_INSIDER_PROCESSED\n",
    "\n",
    "# Get locations to read in\n",
    "file_locs_ = os.listdir(_ri_location)\n",
    "print(f'Found {len(file_locs_)} possible files to analyze')\n",
    "# Filter files for analysis, and append path:\n",
    "file_locs = [_ri_location + f for f in file_locs_ if f[:-7] in isins_to_use]\n",
    "print(f'We are left with {len(file_locs)} to analyze')\n",
    "\n",
    "# Actually read in the company information\n",
    "companies = []\n",
    "print(\"loading return series...\")\n",
    "for file_loc in tqdm(file_locs):\n",
    "    with open(file_loc, \"rb\") as f:\n",
    "        company = pickle.load(f)\n",
    "    companies.append(company)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate Returns, Analyse Companies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Returns\")\n",
    "returns_df = [c.return_index_df.company_return for c in companies]\n",
    "\n",
    "print(\"concatenate\")\n",
    "df_returns = pd.concat(returns_df, axis=1)\n",
    "df_return_index = pd.concat([c.return_index_df for c in companies], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise Mean Daily Returns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick')\n",
    "plt.rc('ytick')\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "returns_companies = df_returns.mean(axis=1)\n",
    "returns_companies.plot(color=\"k\", linewidth=0.7)\n",
    "\n",
    "ax.set_xlabel('Time (Years)', fontsize=label_size)\n",
    "ax.set_ylabel('Mean Daily Return', fontsize=label_size)\n",
    "ax.set_title('Mean Daily Returns Over Time', fontsize=title_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "interval_borders = [\"2018-01-01\", \"2020-03-01\", \"2021-12-31\"] # TODO see if it makes sense to actually take first of Feb\n",
    "\n",
    "for int_ in interval_borders:\n",
    "    plt.axvline(x = int_, color = 'red', label = 'DD Event time', linewidth = 1)\n",
    "\n",
    "plt.savefig(DATA_LOCATION +\"visualisations/NYSE_daily_returns.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "# get var for the intervals\n",
    "print(\"variance of the intervals\")\n",
    "print(f'{round(returns_companies.loc[\"2018-01-01\":\"2020-02-29\"].var(),10):.20f}')\n",
    "print(f'{round(returns_companies.loc[\"2020-03-01\":\"2021-12-31\"].var(), 10):.20f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove companies outside of the timeframe of interest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this is the interval where filings are interesting to us\n",
    "earliest_timestamp = list(investigation_periods.values())[0][0]\n",
    "latest_timestamp = list(investigation_periods.values())[-1][1]\n",
    "filings_removed = 0\n",
    "filings_total = 0\n",
    "\n",
    "for company in tqdm(companies):\n",
    "    insider_data_df = company.insider_data_df\n",
    "    filing_dates = insider_data_df.FilingDate.apply(lambda x: x.floor(\"d\"))\n",
    "    mask = (filing_dates >= earliest_timestamp) & (filing_dates <= latest_timestamp)\n",
    "    company.insider_data_df = company.insider_data_df[mask]\n",
    "    filings_removed += (~mask).sum()\n",
    "    filings_total += mask.shape[0]\n",
    "\n",
    "print(\"Total filings: {}\".format(filings_total))\n",
    "print(\"Removed {} filings\".format(filings_removed))\n",
    "print(\"Remaining filings: {}\".format(filings_total - filings_removed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Investigate Filing Trade Lag Times"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"get filing lags ...\")\n",
    "\n",
    "lags = []\n",
    "for company in tqdm(companies):\n",
    "    lag = UASC.analyse_single_company(company)\n",
    "    lags.append(lag)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filing_trade_lags = sum(lags, [])\n",
    "\n",
    "lag_in_hours = np.asarray(filing_trade_lags)\n",
    "negative_lag_mask = lag_in_hours < 0\n",
    "positive_lag = lag_in_hours[~negative_lag_mask]\n",
    "in_21_days = positive_lag < 21*24\n",
    "relevant_lag = positive_lag[in_21_days]\n",
    "print(f\"Negative lag for {negative_lag_mask.sum()} out of {len(negative_lag_mask)} trades.\")\n",
    "print(f\"Lag longer than 21 days for {len(positive_lag) - len(relevant_lag)} out of {len(negative_lag_mask)} trades.\")\n",
    "print(f\"Eligible trades: {len(relevant_lag)} out of {len(negative_lag_mask)} trades.\")\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 7))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.hist(np.log(positive_lag), bins=\"auto\")\n",
    "ax.set_xlabel('Time (Log(Hours))', fontsize=label_size)\n",
    "ax.set_ylabel('Trades', fontsize=label_size)\n",
    "ax.set_title('Distribution of Log Lag Times between Filing and Trade', fontsize=title_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.axvline(x = 0, color = 'red', label = 'Zero', linewidth = 1)\n",
    "plt.axvline(x = np.log(21*24), color = 'red', label = 'Threshold', linewidth = 1)\n",
    "plt.savefig(DATA_LOCATION +\"visualisations/log_transformed_lags.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "without_outliers = positive_lag[positive_lag < 24*21]\n",
    "\n",
    "fig = plt.figure(figsize=(fig_height, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.hist(without_outliers, bins=\"auto\")\n",
    "plt.xticks(np.arange(0, max(without_outliers) + 1, 24))\n",
    "ax.set_xlabel('Time (Hours)', fontsize=label_size)\n",
    "ax.set_ylabel('Trades', fontsize=label_size)\n",
    "ax.set_title('Distribution of Lag Times between Filing and Trade', fontsize=title_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.savefig(DATA_LOCATION +\"visualisations/lags_without_outliers.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop companies with lags longer than 21 days or negative lags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "removed_lags = 0\n",
    "remaining_lags = 0\n",
    "\n",
    "for lags_c, company in tqdm(zip(lags, companies)):\n",
    "    lags_c = np.asarray(lags_c)\n",
    "    mask_eligible = (lags_c >= 0) & (lags_c <= 21*24)\n",
    "    company.insider_data_df = company.insider_data_df[mask_eligible]\n",
    "    removed_lags += (~mask_eligible).sum()\n",
    "    remaining_lags += mask_eligible.sum()\n",
    "\n",
    "print(f\"Total trades: {removed_lags + remaining_lags}\")\n",
    "print(f\"Removed {removed_lags} trades.\")\n",
    "print(f\"Remaining {remaining_lags} trades.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demonstrate process for a single event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define windows\n",
    "\n",
    "#### Our data contains multiple companies. A single company contains multiple filings and each filing is an event\n",
    "\n",
    "![alt text](assets/images/windows.png \"Title\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Constants defining how long both Estimation Window and Event Window are\n",
    "### Probably also input parameters to a function call, as we need loops later...\n",
    "L1_length = 100\n",
    "L2_length = 40 # TODO +-20 days = 40 days, right?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fix a company"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "if NAME == \"Knudsen\":\n",
    "    company_index = -87\n",
    "elif NAME == \"Niedermayer\":\n",
    "    company_index = -11\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "company = companies[company_index]\n",
    "print(company)\n",
    "company_return = company.return_index_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fix an event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This date will be moved to a loop\n",
    "## Define which periods we are looking at.\n",
    "\n",
    "if NAME == \"Knudsen\":\n",
    "    event_index = 60\n",
    "elif NAME == \"Niedermayer\":\n",
    "    event_index = -200\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "event_timestamp = company.insider_data_df.FilingDate.iloc[event_index].floor(\"d\")\n",
    "print(\"event timestamp: \", event_timestamp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Technical Checks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_checks.run(L1_length, L2_length, event_timestamp, company_return)#, market_timeseries)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#company_return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Determine T0, T1 and T2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T0_, T1_, T2_, T0, T1, T2, ERROR, msg = determine_T0_T1_T2.run(L1_length, L2_length, event_timestamp, company_return)#, market_timeseries)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(event_timestamp)\n",
    "company_return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Abnormal and Normal Returns\n",
    "\n",
    "![alt text](assets/images/return_estimation.png \"Title\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cut return timeseries into correct periods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "windows = cut_timeseries.run(company_return, T0, T1, T2)\n",
    "estimation_window_market_return, estimation_window_company_return, event_window_market_return, event_window_company_return = windows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate coefficients"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alpha, beta, eps = calculate_coefficients.run(estimation_window_market_return, estimation_window_company_return)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Abnormal Return\n",
    "This is the last step of the whole process for one event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "company_return = event_window_company_return\n",
    "market_return = event_window_market_return\n",
    "estimated_return = alpha + beta*market_return\n",
    "abnormal_return = company_return - estimated_return\n",
    "print(abnormal_return)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "company_and_estimated = pd.DataFrame({\"company\":event_window_company_return, \"market\":estimated_return})\n",
    "company_and_market = pd.DataFrame({\"company\": estimation_window_company_return, \"market\":estimation_window_market_return})\n",
    "df_to_plot = pd.concat([company_and_market, company_and_estimated])\n",
    "df_to_plot.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Company_name = company.name\n",
    "\n",
    "# Estimations\n",
    "est_estimation = estimation_window_market_return * beta + alpha\n",
    "est_event = event_window_market_return * beta + alpha\n",
    "\n",
    "plt.figure(figsize=(fig_height,10))\n",
    "estimation_window_market_return.plot(color = 'black', alpha = 0.6, linewidth=4, label = 'Market Return (Estimation Window)')\n",
    "event_window_market_return.plot(color = 'black', alpha = 0.9, linewidth=4, label = 'Market Return (Event Window)')\n",
    "\n",
    "estimation_window_company_return.plot(color = 'blue', alpha = 0.6, linewidth = 4, label = f'{Company_name} Return (Estimation Window)')\n",
    "event_window_company_return.plot(color = 'blue', alpha = 0.9, linewidth = 4, label = f'{Company_name} Return (Event Window)')\n",
    "\n",
    "plt.axvline(x = event_timestamp, color = 'red', label = 'DD Event time', linewidth = 5)\n",
    "plt.ylabel(f'Daily Returns', fontsize=label_size)\n",
    "est_estimation.plot(color = 'green', label = f'Regression Estimate for {Company_name}', alpha = 0.8)\n",
    "est_event.plot(color = 'green', label = f'Regression Estimate for {Company_name}', alpha = 1)\n",
    "\n",
    "plt.axvspan(T0, T1, ymin = 0.05, ymax = 0.95, facecolor='black', alpha=0.1, label = 'Estimation Window', edgecolor='g', linewidth=5)\n",
    "plt.axvspan(T1, T2, ymin = 0.05, ymax = 0.95, facecolor='black', alpha=0.2, label = 'Event Window', edgecolor='r', linewidth=5)\n",
    "plt.legend(bbox_to_anchor = (1.0, 1), loc = 'upper left')\n",
    "\n",
    "plt.title(f'Show how company \"{Company_name}\" moves around the event, compared to the market', fontsize = title_size)\n",
    "plt.xlabel('Date', fontsize=label_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.show()\n",
    "print(\"I'm impressed! It looks like a five-year-old drew this plot in paint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Macro Analysis\n",
    "\n",
    "### Now that we have seen the process for one single filing, let us do the same for all filings in all companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize testing\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "# Helpers\n",
    "multiind, data, data_errors = [], [], []\n",
    "estimation_window_market_return_list, event_window_market_return_list, eps_list = [], [], []\n",
    "n_companies = len(companies)\n",
    "\n",
    "\n",
    "#for j in tqdm(range(len(companies[:200]))):\n",
    "for j in tqdm(range(len(companies))):\n",
    "    # Get information from said company\n",
    "    company = companies[j]\n",
    "    company_return = company.return_index_df\n",
    "    \n",
    "    n_filings = len(company.insider_data_df)\n",
    "    # Go through all filings\n",
    "    for i in company.insider_data_df.FilingDate.index:\n",
    "\n",
    "        # Find our event date from filing\n",
    "        filing_date = company.insider_data_df.FilingDate[i]\n",
    "        event_timestamp = filing_date.floor(\"d\")\n",
    "\n",
    "        checks = data_checks.run(L1_length, L2_length, event_timestamp, company_return)\n",
    "        if checks:\n",
    "            #print(checks[1])\n",
    "            data_errors.append(checks[0])\n",
    "            continue\n",
    "   \n",
    "        ## Proceed to find periods\n",
    "        T0_, T1_, T2_, T0, T1, T2, ERRORS, msg = determine_T0_T1_T2.run(L1_length, L2_length, event_timestamp, company_return)\n",
    "        if ERRORS:\n",
    "            #print(msg)\n",
    "            data_errors.append(ERRORS)\n",
    "            continue\n",
    "            \n",
    "        ## Cut timeseries to the relevant periods, and split them\n",
    "        windows = cut_timeseries.run(company_return, T0, T1, T2)\n",
    "        estimation_window_market_return, estimation_window_company_return,event_window_market_return, event_window_company_return = windows\n",
    "        alpha, beta, eps = run(estimation_window_market_return, estimation_window_company_return) # TODO change back to calculate_coefficients.run or check validity\n",
    "        ## Calculate the abnormal returns\n",
    "        abnormal_return = event_window_company_return - alpha - beta*event_window_market_return\n",
    "        \n",
    "        ## Append to results\n",
    "        estimation_window_market_return_list.append(estimation_window_market_return)\n",
    "        event_window_market_return_list.append(event_window_market_return)\n",
    "        eps_list.append(eps)\n",
    "        multiind.append((company.ticker, i, company.insider_data_df.TradeType[i], event_timestamp))\n",
    "        data.append(abnormal_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# process and save abnormal returns\n",
    "df_abnormal_returns = pd.DataFrame.from_records([d.reset_index(drop=True) for d in data])\n",
    "df_abnormal_returns.index = pd.MultiIndex.from_tuples(multiind, names=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_abnormal_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_estimation_window_market_return = pd.DataFrame.from_records([d.reset_index(drop=True) for d in estimation_window_market_return_list])\n",
    "df_estimation_window_market_return.index = pd.MultiIndex.from_tuples(multiind, names=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_event_window_market_return = pd.DataFrame.from_records([d.reset_index(drop=True) for d in event_window_market_return_list])\n",
    "df_event_window_market_return.index = pd.MultiIndex.from_tuples(multiind, names=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_eps = pd.DataFrame.from_records([d for d in eps_list])\n",
    "df_eps.index = pd.MultiIndex.from_tuples(multiind, names=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Show the reasons filings were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "errors_df = pd.DataFrame.from_records(data_errors)\n",
    "errors_agg = errors_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add earlier filtering\n",
    "errors_agg[\"event not in overall time frame\"] = filings_removed\n",
    "errors_agg[\"negative lags\"] = negative_lag_mask.sum()\n",
    "errors_agg[\"more than 21 days lag\"] = len(positive_lag) - len(relevant_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "errors_agg = pd.DataFrame(errors_agg)\n",
    "errors_agg.index.name = \"Reason\"\n",
    "errors_agg.columns = [\"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(errors_agg.astype(int).reset_index().to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(errors_agg.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_abnormal_returns.to_pickle(f\"data/{NAME}/calculate_AR_results/df_abnormal_returns.pkl\")\n",
    "df_estimation_window_market_return.to_pickle(f\"data/{NAME}/calculate_AR_results/df_estimation_window_market_return.pkl\")\n",
    "df_event_window_market_return.to_pickle(f\"data/{NAME}/calculate_AR_results/df_event_window_market_return.pkl\")\n",
    "df_eps.to_pickle(f\"data/{NAME}/calculate_AR_results/df_eps.pkl\")\n",
    "\n",
    "with open(f\"data/{NAME}/calculate_AR_results/companies.pkl\", \"wb\") as f:\n",
    "    pickle.dump(companies, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}