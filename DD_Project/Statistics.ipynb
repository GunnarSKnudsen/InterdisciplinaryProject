{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Statistics and Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"Knudsen\"\n",
    "NAME = \"Niedermayer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Niedermayer/calculate_AR_results/df_abnormal_returns.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mstats\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# unpickle the abnormal returns\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m df_abnormal_returns \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_pickle\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mNAME\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/calculate_AR_results/df_abnormal_returns.pkl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# set plotting sizes\u001B[39;00m\n\u001B[0;32m     13\u001B[0m tick_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m15\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\IDP\\lib\\site-packages\\pandas\\io\\pickle.py:187\u001B[0m, in \u001B[0;36mread_pickle\u001B[1;34m(filepath_or_buffer, compression, storage_options)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;124;03m4    4    9\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[0;32m    186\u001B[0m excs_to_catch \u001B[38;5;241m=\u001B[39m (\u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mImportError\u001B[39;00m, \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m)\n\u001B[1;32m--> 187\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    194\u001B[0m \n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# 1) try standard library Pickle\u001B[39;00m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001B[39;00m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001B[39;00m\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001B[39;00m\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\IDP\\lib\\site-packages\\pandas\\io\\common.py:798\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    790\u001B[0m             handle,\n\u001B[0;32m    791\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    794\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    795\u001B[0m         )\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/Niedermayer/calculate_AR_results/df_abnormal_returns.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# unpickle the abnormal returns\n",
    "df_abnormal_returns = pd.read_pickle(f\"data/{NAME}/calculate_AR_results/df_abnormal_returns.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "# set plotting sizes\n",
    "tick_size = 15\n",
    "label_size = 20\n",
    "title_size = 30\n",
    "fig_height = 20\n",
    "\n",
    "EVENT_INDEX = 20 # because 20 [0,..19] are before the event\n",
    "\n",
    "\n",
    "investigation_periods = {\n",
    "    \"overall\": (pd.Timestamp(\"2018-01-01\"), pd.Timestamp(\"2021-12-31\")),\n",
    "    \"pre-pandemic\": (pd.Timestamp(\"2018-01-01\"), pd.Timestamp(\"2020-02-29\")),\n",
    "    \"pandemic\": (pd.Timestamp(\"2020-03-01\"), pd.Timestamp(\"2021-12-31\")),\n",
    "}\n",
    "\n",
    "with open(f\"data/{NAME}/calculate_AR_results/companies.pkl\", \"rb\") as f:\n",
    "    companies = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Having a look at all trade types together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "types_of_interest = [\"P - Purchase\", \"S - Sale\", \"S - Sale+OE\"]\n",
    "counts = df_abnormal_returns.groupby(level=2).count()[0].rename({0: \"N\"})\n",
    "print(f\"relevant filings: \",counts[types_of_interest].sum())\n",
    "print(counts[types_of_interest])\n",
    "print(f\"dropped filings \", counts.sum() - counts[types_of_interest].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = df_abnormal_returns.loc[:,:,types_of_interest,:].groupby(level=[2]).mean().transpose().plot(figsize=(fig_height, 10))\n",
    "plt.plot(np.zeros(len(df_abnormal_returns.columns)), color=\"black\", linewidth=0.5)\n",
    "a.set_title(\"Mean Abnormal Returns Of Selected Trade Types\",fontsize=title_size)\n",
    "a.set_xlabel(\"Days\", fontsize=label_size)\n",
    "a.set_ylabel(\"Mean Abnormal Return\", fontsize=label_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.axvline(x = EVENT_INDEX, color = 'red', label = 'DD Event time', linewidth = 1.5)\n",
    "plt.savefig(f\"data/{NAME}/visualisations/MAR_selected_tradetypes.png\", dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = df_abnormal_returns.loc[:,:,types_of_interest,:].groupby(level=[2]).mean().transpose().cumsum().plot(figsize=(fig_height, 10))\n",
    "plt.plot(np.zeros(len(df_abnormal_returns.columns)), color=\"black\", linewidth=0.5)\n",
    "a.set_title(\"Cumulative Abnormal Returns Of Selected Trade Types\",fontsize=title_size)\n",
    "a.set_xlabel(\"Days\", fontsize=label_size)\n",
    "a.set_ylabel(\"Cumulative Abnormal Return\", fontsize=label_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.axvline(x = EVENT_INDEX, color = 'red', label = 'DD Event time', linewidth = 1.5)\n",
    "plt.savefig(f\"data/{NAME}/visualisations/CAR_selected_tradetypes.png\", dpi=600, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = df_abnormal_returns.groupby(level=[2]).mean().transpose().plot(figsize=(fig_height, 10), fontsize=15)\n",
    "plt.plot(np.zeros(len(df_abnormal_returns.columns)), color=\"black\", linewidth=0.5)\n",
    "a.set_title(\"Abnormal Returns of all Trade Types\",fontsize=title_size)\n",
    "a.set_xlabel(\"Days\", fontsize=label_size)\n",
    "a.set_ylabel(\"Mean Abnormal Return\", fontsize=label_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "plt.axvline(x = EVENT_INDEX, color = 'red', label = 'DD Event time', linewidth = 1.5)\n",
    "plt.savefig(f\"data/{NAME}/visualisations/AR_all_tradetypes.png\", dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_abnormal_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "I think OE and OptEx means option exercise. \"to exercise\" means to put into effect the right to buy or sell the underlying security that is specified in the options contract.\" Can we be sure that the action does not shift the market, and the swing in return is really due to new information? Are these trades public, so maybe they are used as a signal for traders?\n",
    "\n",
    "### Boxplot of the sum over all companies's AR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![alt text](assets/images/time_agg.png)\n",
    "\n",
    "In our case it is not company i, but filing i\n",
    "\n",
    "Types of trade to pick from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = df_abnormal_returns.groupby(level=[2]).sum().transpose().plot.box(rot=90, figsize=(fig_height, 10))\n",
    "ax.set_title(\"Boxplots of the Abnormal Returns for each Trade Type\",fontsize=title_size)\n",
    "ax.set_xlabel(\"Trade Type\", fontsize=label_size)\n",
    "ax.set_ylabel(\"Abnormal Return\", fontsize=label_size)\n",
    "\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.savefig(f\"data/{NAME}/visualisations/AR_all_tradetypes_boxplot.png\", dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "types = list(set([x[2] for x in df_abnormal_returns.index]))\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Specify the type of the trades to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type_ = \"P - Purchase\" # \"S - Sale\"\n",
    "df_abnormal_returns_type = df_abnormal_returns.loc[:,:,type_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The index describes the company and the index of the filing in the compnay, the columns represent the days in the event window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_abnormal_returns_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_abnormal_returns_type.sum(axis=0).plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CAR = df_abnormal_returns_type.cumsum(axis=0)\n",
    "CAR.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![alt text](assets/images/cross_sectional_agg.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AR_bar = df_abnormal_returns_type.mean(axis=0) \n",
    "AR_bar.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CAR_bar = AR_bar.sum()\n",
    "CAR_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO var_CAR_bar = Does the definition make sense? It seems like we take the var of a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![alt text](assets/images/cross_sectional_agg2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CAR_bar_2 = CAR.mean()\n",
    "CAR_bar_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# var car TODO not sure what just sigma means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Statistics\n",
    "\n",
    "Check if CAR mean = 0 (t-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# unpickle the data\n",
    "df_eps = pd.read_pickle(f\"data/{NAME}/calculate_AR_results/df_eps.pkl\")\n",
    "df_estimation_window_market_return = pd.read_pickle(f\"data/{NAME}/calculate_AR_results/df_estimation_window_market_return.pkl\")\n",
    "df_event_window_market_return = pd.read_pickle(f\"data/{NAME}/calculate_AR_results/df_event_window_market_return.pkl\")\n",
    "\n",
    "df_eps.sort_index(level=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"], ascending=True, inplace=True)\n",
    "df_estimation_window_market_return.sort_index(level=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"], ascending=True, inplace=True)\n",
    "df_event_window_market_return.sort_index(level=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"], ascending=True, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from source.statistical_tests import grank, adjBMP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_eps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_abnormal_returns.sort_index(level=[\"Company\", \"i\", \"TradeType\", \"event_timestamp\"], ascending=True, inplace=True)\n",
    "left, right = investigation_periods[\"pandemic\"]\n",
    "df_abnormal_returns.loc[:,:,type_, left:right]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_results = []\n",
    "test_index = []\n",
    "\n",
    "for per in investigation_periods.keys():\n",
    "    for type_ in types_of_interest:\n",
    "        left, right = investigation_periods[per]\n",
    "        AR = df_abnormal_returns.loc[:,:,type_, left:right].values\n",
    "        eps = df_eps.loc[:,:,type_,left:right].values\n",
    "        R_market_estimation_window = df_estimation_window_market_return.loc[:,:,type_,left:right].values\n",
    "        R_market_event_window = df_event_window_market_return.loc[:,:,type_,left:right].values\n",
    "        event_day = 20\n",
    "        grank_result = grank(AR, eps, R_market_estimation_window, R_market_event_window, event_day)\n",
    "        adjBMP_result = adjBMP(AR, eps, R_market_estimation_window, R_market_event_window, event_day)\n",
    "        test_results.append((grank_result.pvalue, adjBMP_result.pvalue))\n",
    "        test_index.append((per, type_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(test_results, columns=[\"GRANK\", \"adj-BMP\"], index=pd.MultiIndex.from_tuples(test_index))\n",
    "print(test_results_df.round(5).to_latex())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tt = stats.ttest_1samp(CAR, popmean=0)\n",
    "tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check if CAR median = 0 (wilcoxon signed rank test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stats.wilcoxon(CAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "types = types\n",
    "investigation_periods = investigation_periods\n",
    "multiind_p, data_p = [], []\n",
    "\n",
    "event_day_ranges = {\n",
    "    \"pre-event\": (0,20), # TODO for now we drop the filing day itself\n",
    "    \"post-event\": (21,41)\n",
    "}\n",
    "\n",
    "tests = {\"ttest\": lambda x: round(stats.ttest_1samp(x, popmean=0).pvalue, 10),\n",
    "         \"wilcoxon\": lambda x: round(stats.wilcoxon(x).pvalue,10)}\n",
    "\n",
    "aggregation_type = {\"name\": \"cross-sectional\", \"axis\":0}\n",
    "#aggregation_type = {\"name\": \"through time\", \"axis\":1}\n",
    "\n",
    "for type_ in types:\n",
    "    for per in investigation_periods.keys():\n",
    "        for side in event_day_ranges.keys():\n",
    "                \n",
    "            event_day_range = event_day_ranges[side]\n",
    "            df_abnormal_returns_type = df_abnormal_returns.loc[:,:,type_]\n",
    "            per_left, per_right = investigation_periods[per]\n",
    "\n",
    "\n",
    "            timestamps = df_abnormal_returns_type.index.get_level_values(2)\n",
    "            mask = (timestamps >= per_left) & (timestamps <= per_right)\n",
    "            df_AR_type_per = df_abnormal_returns_type[mask]\n",
    "            if not len(df_AR_type_per):\n",
    "                print(f\"skipping iteration because of 0 datapoints {(type_, per, side)}\")\n",
    "                continue\n",
    "            df_AR_type_per_side = df_AR_type_per.iloc[:,event_day_range[0]:event_day_range[1]]\n",
    "            CAR = df_AR_type_per_side.mean(axis=aggregation_type[\"axis\"]).cumsum()\n",
    "\n",
    "            pvalue_ttest = tests[\"ttest\"](CAR)\n",
    "            pvalue_wilcoxon = tests[\"wilcoxon\"](CAR)\n",
    "            mean = CAR.mean()\n",
    "            median = CAR.median()\n",
    "            # calculate a 95% confidence interval\n",
    "            left, right = stats.t.interval(0.95, len(CAR)-1, loc=np.mean(CAR), scale=stats.sem(CAR))\n",
    "            left, right = round(left, 4), round(right, 4)\n",
    "            CI = left, right\n",
    "            \n",
    "            multiind_p.append((type_, per, side))\n",
    "            data_p.append((mean, pvalue_ttest, median, pvalue_wilcoxon, len(df_AR_type_per), CI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# process abnormal returns\n",
    "df_p = pd.DataFrame.from_records(data_p)\n",
    "df_p.index = pd.MultiIndex.from_tuples(multiind_p, names=[\"TradeType\", \"Period\", \"Side\"])\n",
    "df_p.columns = [\"mean\", \"ttest pvalue\", \"median\", \"wilcoxon pvalue\", \"sample_size\", \"95% CI\"]\n",
    "df_p.to_csv(f\"data/{NAME}/{aggregation_type['name']}_tests_result.csv\")\n",
    "df_p.sort_values(\"ttest pvalue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_p.loc[\"S - Sale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Export information to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for t in types:\n",
    "    counter = counter+1\n",
    "    #print(t)\n",
    "    df_ = df_p.loc[t,:,:]\n",
    "    df_ = df_.rename(columns={'Side of the event': 'Side'\n",
    "                              , 'mean': 'mean'\n",
    "                              , 'ttest pvalue': 'ttest'\n",
    "                              , 'median': 'median'\n",
    "                              , 'wilcoxon pvalue': 'Wilcoxon'\n",
    "                              , 'sample_size': 'N'})\n",
    "    #display(df_)\n",
    "    \n",
    "    latex = df_.drop(columns=[\"95% CI\"])\\\n",
    "    .to_latex( column_format=\"llrrrrr\"\n",
    "              , position=\"H\"\n",
    "              , label=f\"table:t{counter}_hypothesistest\"\n",
    "              , caption= f\"Hypothesis tests for type: {t}\"\n",
    "              #, index = False\n",
    "    )\n",
    "    print(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualise CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# purcase, sale and sale with oe\n",
    "for t in types_of_interest:\n",
    "    for side in event_day_ranges.keys():\n",
    "\n",
    "        df_ = df_p.loc[t,:,side]\n",
    "\n",
    "        def plot_confidence_interval(x, mean, CI, color='#2187bb', horizontal_line_width=0.25):\n",
    "\n",
    "\n",
    "            left = x - horizontal_line_width / 2\n",
    "            top = mean - CI\n",
    "            right = x + horizontal_line_width / 2\n",
    "            bottom = mean + CI\n",
    "            plt.plot([x, x], [top, bottom], color=color)\n",
    "            plt.plot([left, right], [top, top], color=color)\n",
    "            plt.plot([left, right], [bottom, bottom], color=color)\n",
    "            plt.plot(x, mean, 'o', color='#f44336')\n",
    "\n",
    "            return mean, CI\n",
    "\n",
    "        plt.figure(figsize=(fig_height,4))\n",
    "\n",
    "        df_to_plot = df_\n",
    "        for i, row in enumerate(df_to_plot.sort_values(\"mean\").itertuples()):\n",
    "            mean, CI = plot_confidence_interval(i, row[1], row[6][1] - row[1])\n",
    "\n",
    "        plt.plot(np.zeros(len(df_to_plot)), color=\"black\", linewidth=0.5)\n",
    "        plt.xticks(range(len(df_to_plot)), df_to_plot.index, fontsize=tick_size)\n",
    "        plt.yticks(fontsize=tick_size)\n",
    "\n",
    "        plt.title(f'CI of trade type  {t} | {side} abnormal return data ', fontsize=title_size)\n",
    "\n",
    "        plt.xlabel('Time Frame', fontsize=label_size)\n",
    "        plt.ylabel('Mean Abnormal Return', fontsize=label_size)\n",
    "\n",
    "        plt.xticks(fontsize=tick_size)\n",
    "        plt.yticks(fontsize=tick_size)\n",
    "        plt.savefig(f\"data/{NAME}/visualisations/CI_{t}_{side}.png\", dpi=600, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "multiind_h3, data_h3 = [], []\n",
    "\n",
    "two_sample_tests = {\n",
    "    \"ttest\": lambda x, y: round(stats.ttest_ind(x, y).pvalue, 10),\n",
    "    \"wilcoxon\": lambda x, y: round(stats.wilcoxon(x, y).pvalue, 10)\n",
    "}\n",
    "\n",
    "for test_name in two_sample_tests.keys():\n",
    "    for t in types_of_interest:\n",
    "        d = []\n",
    "        for side in event_day_ranges.keys():\n",
    "\n",
    "            event_day_range = event_day_ranges[side]\n",
    "            df_abnormal_returns_type = df_abnormal_returns.loc[:,:,t]\n",
    "\n",
    "            timestamps = df_abnormal_returns_type.index.get_level_values(2)\n",
    "\n",
    "            df_AR_type_side = df_abnormal_returns_type.iloc[:,event_day_range[0]:event_day_range[1]]\n",
    "\n",
    "\n",
    "            pand_start, pand_end = investigation_periods[\"pandemic\"][0], investigation_periods[\"pandemic\"][1]\n",
    "            prepand_start, prepand_end = investigation_periods[\"pre-pandemic\"][0], investigation_periods[\"pre-pandemic\"][1]\n",
    "\n",
    "            mask_pand = (timestamps >= pand_start) & (timestamps <= pand_end)\n",
    "            mask_prepand = (timestamps >= prepand_start) & (timestamps <= prepand_end)\n",
    "\n",
    "            df_AR_type_side_pand_agg = df_AR_type_side[mask_pand].mean(axis=0).cumsum()\n",
    "            df_AR_type_side_prepand_agg = df_AR_type_side[mask_prepand].mean(axis=0).cumsum()\n",
    "            plt.hist(df_AR_type_side_pand_agg)\n",
    "            plt.hist(df_AR_type_side_prepand_agg)\n",
    "            plt.show()\n",
    "\n",
    "            pvalue = two_sample_tests[test_name](df_AR_type_side_prepand_agg, df_AR_type_side_pand_agg)\n",
    "            print(f\"For type {t}, in the days {side} of the event, the pre-pandemic and pandemic mean of abnormal returns is different with a p-value of {pvalue}\")\n",
    "\n",
    "            d.append(pvalue)\n",
    "        multiind_h3.append((test_name, t))\n",
    "        data_h3.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### P-values of whether pre-pandemic and pandemic are significantly different for the timeframe before and after the event and different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_h3 = pd.DataFrame(data_h3, columns=event_day_ranges.keys())\n",
    "df_h3.index=pd.MultiIndex.from_tuples(multiind_h3, names=[\"Test\", \"Type\"])\n",
    "df_h3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(df_h3.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Specify the type of the trades to investigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize how active Directors Dealings Are\n",
    "Should move this to somewhere else\n",
    "Want visual confirmation that Directors have changed behaviour during the times of Covid (Hypothesis 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades = companies[0].insider_data_df.head(0)\n",
    "from tqdm import tqdm\n",
    "#for j in tqdm(range(len(companies[:200]))):\n",
    "for j in tqdm(range(len(companies))):\n",
    "    all_insider_trades = pd.concat([all_insider_trades, companies[j].insider_data_df])#  @ gunnar very nice asymptotic runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades['FilingDateTrunc'] = all_insider_trades['FilingDate'].dt.date\n",
    "all_insider_trades.groupby('FilingDateTrunc')['FilingDate'].count().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades.to_csv('AllTradesForExcelGSK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades.groupby('FilingDateTrunc')['Value'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_insider_trades.groupby('FilingDateTrunc')['Value'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(all_insider_trades['FilingDateTrunc'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}