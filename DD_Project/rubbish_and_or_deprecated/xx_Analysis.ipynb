{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Open quesions:\n",
    "    * What to do with missing days (e.g. 2019-11-28 [Thanksgivbing])\n",
    "    * Non-unique tickers/isins\n",
    "    * ~~ --__**L1 and L2 lengths - currently calendar days - should be trading days? - Might make BIG difference when aggregating**__-- ~~\n",
    "    * Am currently lengthening when Market and Company aren't the same. Is this correct?\n",
    "    * Also, check what the heck actually is in \"company_returns\"... Should probably re-understand that code once more...\n",
    "    * How do we do with periods out of range w.r.t. indexes? - Fix this!\n",
    "    * Currently always from Company - but should compare with market as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Time Cleaning\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Scraping\n",
    "import requests\n",
    "import locale\n",
    "from pandas.io.json import json_normalize\n",
    "import io\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels import regression\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import User Defined functions\n",
    "import source.read_tickers_and_isins as URTI\n",
    "import source.get_directors_dealings as UGDD\n",
    "import source.get_timeseries as UGT\n",
    "import source.analyze_get_summary_of_data as AGSOD\n",
    "import source.preprocess_directors_dealings as UPDD\n",
    "import source.preprocess_timeseries as UPTS\n",
    "import source.preprocess_timeseries_from_excel as UPTFE\n",
    "import source.analyse_single_company as UASC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read in single company to \"analyze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEOFError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(file_loc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28mtype\u001B[39m \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[1;32m---> 18\u001B[0m     isin \u001B[38;5;241m=\u001B[39m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     name \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m     20\u001B[0m     ticker \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n",
      "\u001B[1;31mEOFError\u001B[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "_isin = 'US02376R1023'\n",
    "\n",
    "\n",
    "NAME = \"Knudsen\"\n",
    "DATA_LOCATION = f'data/{NAME}/'\n",
    "DATA_LOCATION_INSIDER_RAW = DATA_LOCATION + 'raw/insider/'\n",
    "DATA_LOCATION_INSIDER_PROCESSED = DATA_LOCATION + 'processed/insider/'\n",
    "DATA_LOCATION_TIME_SERIES_RAW = DATA_LOCATION + 'raw/timeseries/'\n",
    "DATA_LOCATION_TIME_SERIES_PROCESSED = DATA_LOCATION + 'processed/timeseries/'\n",
    "DATA_LOCATION_RI = DATA_LOCATION + 'processed/RI/'\n",
    "\n",
    "_ri_location = DATA_LOCATION_RI\n",
    "_insider_location = DATA_LOCATION_INSIDER_PROCESSED\n",
    "\n",
    "file_loc = _ri_location + _isin + '.pickle'\n",
    "with open(file_loc, \"rb\") as f:\n",
    "    type = pickle.load(f)\n",
    "    isin = pickle.load(f)\n",
    "    name = pickle.load(f)\n",
    "    ticker = pickle.load(f)\n",
    "    start_date = pickle.load(f)\n",
    "    end_date = pickle.load(f)\n",
    "    return_index_df = pickle.load(f)\n",
    "#display(return_index_df)\n",
    "\n",
    "company_return = return_index_df\n",
    "display(company_return)\n",
    "\n",
    "# Probably need a try/catch here\n",
    "insider_data_df = pd.read_csv(_insider_location + ticker + '.csv', index_col=0, parse_dates=['FilingDate', 'TradeDate'])\n",
    "#display(insider_data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get market timeseries - used for \"normal returns\"\n",
    "\n",
    "Move this to somewhere that makes sense\n",
    "\n",
    "Perfect! seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "end_time = datetime.datetime(2022, 3, 21, 23, 59, 59)\n",
    "_end_time_unix = int(time.mktime(end_time.timetuple()))\n",
    "print(_end_time_unix)\n",
    "\n",
    "start_time = datetime.datetime(2016, 3, 21, 0, 0, 0)\n",
    "_start_time_unix = int(time.mktime(start_time.timetuple()))\n",
    "\n",
    "print(_start_time_unix)\n",
    "_ticker = '%5EIXIC'\n",
    "\n",
    "url = f'https://query1.finance.yahoo.com/v7/finance/download/{_ticker}?period1={_start_time_unix}&period2={_end_time_unix}&interval=1d&events=history&includeAdjustedClose=true'\n",
    "\n",
    "market_timeseries = pd.read_csv(url)\n",
    "market_timeseries = market_timeseries.set_index('Date')\n",
    "market_timeseries.index = market_timeseries.index.astype('datetime64[ns]')\n",
    "\n",
    "market_timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define Events windows (PEF_8 page 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# This date will be moved to a loop\n",
    "## Define which periods we are looking at.\n",
    "event_timestamp = insider_data_df['FilingDate'][0].floor('d')\n",
    "\n",
    "## Constants defining how long both Estimation Window and Event Window are - See page 34 in PEF_8\n",
    "### Probably also input parameters to a function call, as we need loops later...\n",
    "L1_length = 100\n",
    "L2_length = 20\n",
    "\n",
    "\n",
    "# Check if we have enough data to run analysis:\n",
    "## I get a bunch of Out of bounds errors when events happen too close to the border of available data. Did a bunch of cleansing, before realiing that it is WAY easier to just throw errors then.\n",
    "## Let's see if we can handle this better...\n",
    "\n",
    "# Constants that are being checked\n",
    "## We need to have this data:\n",
    "required_days_before_event = L1_length + L2_length\n",
    "required_days_after_event = L2_length\n",
    "VERY_minimum_days_required = required_days_before_event + required_days_after_event + 1 # VERY not relavant at all... - If this fails; the two other checks will as well\n",
    "\n",
    "## We have this data:\n",
    "company_length = company_return.shape[0]\n",
    "market_length = market_timeseries.shape[0]\n",
    "\n",
    "### This is the location of the event that is being checked:\n",
    "event_index_company = company_return.index.get_loc(event_timestamp)\n",
    "event_index_market = market_timeseries.index.get_loc(event_timestamp)\n",
    "\n",
    "# I want all errors logged, hence a flag - would make way more sense to break in the check itself\n",
    "ERROR_HAS_OCCURED = 0\n",
    "\n",
    "# Do worlds most unnecesary check\n",
    "if (company_length < VERY_minimum_days_required):\n",
    "    print(f\"Analysis can't be done. Requires data length of {VERY_minimum_days_required} trading days. However we only have {company_length} trading days for the company information\")\n",
    "    ERROR_HAS_OCCURED = 1\n",
    "    \n",
    "if (market_length < VERY_minimum_days_required):\n",
    "    print(f\"Analysis can't be done. Requires data length of {VERY_minimum_days_required} trading days. However we only have {market_length} trading days for the market information\")\n",
    "    ERROR_HAS_OCCURED = 1\n",
    "\n",
    "if (required_days_before_event >= event_index_company): # Check if smaller or smaller or equal is correct\n",
    "    print(f\"Analysis can't be done. Requires at least {required_days_before_event} trading days before the event. However we only have {event_index_company} entries prior in the company data\")\n",
    "    ERROR_HAS_OCCURED = 1\n",
    "          \n",
    "if (required_days_before_event >= event_index_market): # Check if smaller or smaller or equal is correct\n",
    "    print(f\"Analysis can't be done. Requires at least {required_days_before_event} trading days before the event. However we only have {event_index_market} entries prior in the market data\")\n",
    "    ERROR_HAS_OCCURED = 1\n",
    "\n",
    "if (required_days_after_event >= (company_length - event_index_company)): # Check if smaller or smaller or equal is correct\n",
    "    print(f\"Analysis can't be done. Requires at least {required_days_after_event} trading days AFTER the event. However we only have {(company_length - event_index_company)} entries available after in the company data\")\n",
    "    ERROR_HAS_OCCURED = 1\n",
    "    \n",
    "if (required_days_after_event >= (market_length - event_index_market)): # Check if smaller or smaller or equal is correct\n",
    "    print(f\"Analysis can't be done. Requires at least {required_days_after_event} trading days AFTER the event. However we only have {(market_length - event_index_market)} entries available after in the market data\")\n",
    "    ERROR_HAS_OCCURED = 1\n",
    "\n",
    "if ERROR_HAS_OCCURED == 1:\n",
    "    raise SystemExit(\"You saw it already - we've got errors and shite!\") # Switch to break or return once I'm done playing around\n",
    "\n",
    "# Yay! If you've come this far; we can start the analysis!\n",
    "\n",
    "\n",
    "# Event-Window (L2):\n",
    "## Discard this solution - this takes calendar-days; should be trading days!\n",
    "#T1 = event_timestamp - datetime.timedelta(days = L2_length)\n",
    "#T2 = event_timestamp + datetime.timedelta(days = L2_length)\n",
    "\n",
    "T1_c_iloc = company_return.index.get_loc(event_timestamp)-L2_length\n",
    "T1_m_iloc = market_timeseries.index.get_loc(event_timestamp)-L2_length\n",
    "\n",
    "# Fairly certain this block can be deleted now that I've implemented the checks above...\n",
    "#if T1_c_iloc < 0:\n",
    "#    T1_c_iloc = 0\n",
    "    \n",
    "#if T1_m_iloc < 0:\n",
    "#    T1_m_iloc = 0\n",
    "\n",
    "T1_c = company_return.index[T1_c_iloc]\n",
    "T1_m = market_timeseries.index[T1_m_iloc]\n",
    "\n",
    "# Do this magic BEFORE calculating T0 - Otherwise we risk breaking!\n",
    "if (T1_c < T1_m):\n",
    "    T1 = T1_c\n",
    "else:\n",
    "    T1 = T1_m\n",
    "\n",
    "print(f'Found T1: {str(T1)}')\n",
    "    \n",
    "T2_c_iloc = company_return.index.get_loc(event_timestamp)+L2_length\n",
    "T2_m_iloc = market_timeseries.index.get_loc(event_timestamp)+L2_length\n",
    "\n",
    "# Fairly certain this block can be deleted now that I've implemented the checks above...\n",
    "#if T2_c_iloc > company_return.shape[0]-1:\n",
    "#    T2_c_iloc = company_return.shape[0]-1\n",
    "    \n",
    "#if T2_m_iloc > market_timeseries.shape[0]-1:\n",
    "#    T2_m_iloc = market_timeseries.shape[0]-1\n",
    "\n",
    "T2_c = company_return.index[T2_c_iloc]\n",
    "T2_m = market_timeseries.index[T2_m_iloc]\n",
    "\n",
    "if (T2_c > T2_m):\n",
    "    T2 = T2_c\n",
    "else:\n",
    "    T2 = T2_m\n",
    "\n",
    "print(f'Found T2: {str(T2)}')\n",
    "\n",
    "# Estimation Window:\n",
    "#T0 = T1 - datetime.timedelta(days = L1_length)\n",
    "\n",
    "T0_c_iloc = company_return.index.get_loc(T1)-L1_length\n",
    "T0_m_iloc = market_timeseries.index.get_loc(T1)-L1_length\n",
    "\n",
    "# Fairly certain this block can be deleted now that I've implemented the checks above...\n",
    "#if T0_c_iloc < 0:\n",
    "#    T0_c_iloc = 0\n",
    "    \n",
    "#if T2_m_iloc < 0:\n",
    "#    T2_m_iloc = 0\n",
    "\n",
    "T0_c = company_return.index[T0_c_iloc]\n",
    "T0_m = market_timeseries.index[T0_m_iloc]\n",
    "\n",
    "if (T0_c < T0_m):\n",
    "    T0 = T0_c\n",
    "else:\n",
    "    T0 = T0_m\n",
    "    \n",
    "print(f'Found T0: {str(T0)}')\n",
    "\n",
    "## Break T0 and T1 to cheat so we don't start with NAs\n",
    "#T1_ = T1 - datetime.timedelta(days = 1)\n",
    "#T0_ = T0 - datetime.timedelta(days = 1)\n",
    "T1_ = company_return.index[company_return.index.get_loc(T1)-1]\n",
    "T0_ = company_return.index[company_return.index.get_loc(T0)-1]\n",
    "\n",
    "\n",
    "print(f'------------------------------')\n",
    "print(f'Event occurred at             {event_timestamp}')\n",
    "print(f'Estimation Window ({str(L1_length)} days): from {str(T0)} to {str(T1)}')\n",
    "print(f'Event Window      ( {str(L2_length)} days): from {str(T1)} to {str(T0)}')\n",
    "\n",
    "# Cut return timeseries into correct periods\n",
    "\n",
    "## Estimation Window\n",
    "### For estimating alphas and betas\n",
    "estimation_window_index_market = (market_timeseries.index >= T0_) & (market_timeseries.index < T1)\n",
    "estimation_window_index_company = (company_return.index >= T0_) & (company_return.index < T1)\n",
    "\n",
    "estimation_window_market_timeseries = market_timeseries[estimation_window_index_market]\n",
    "estimation_market_count = estimation_window_market_timeseries.shape[0]\n",
    "\n",
    "estimation_window_company_timeseries = company_return[estimation_window_index_company]\n",
    "estimation_company_count = estimation_window_company_timeseries.shape[0]\n",
    "\n",
    "## Event-Window\n",
    "event_window_index_market = (market_timeseries.index >= T1_) & (market_timeseries.index < T2)\n",
    "event_window_index_company = (company_return.index >= T1_) & (company_return.index < T2)\n",
    "\n",
    "event_window_market_timeseries = market_timeseries[event_window_index_market]\n",
    "event_market_count = event_window_market_timeseries.shape[0]\n",
    "\n",
    "event_window_company_timeseries = company_return[event_window_index_company]\n",
    "event_company_count = event_window_company_timeseries.shape[0]\n",
    "\n",
    "print('shape before aggregating')\n",
    "print(f'# estimation_window_market_timeseries: {estimation_window_market_timeseries.shape}')\n",
    "print(f'# estimation_window_company_timeseries: {estimation_window_company_timeseries.shape}')\n",
    "print(f'# event_window_market_timeseries: {event_window_market_timeseries.shape}')\n",
    "print(f'# event_window_company_timeseries: {event_window_company_timeseries.shape}')\n",
    "\n",
    "\n",
    "# Unify indexing, so that both contain same amount of trading days.\n",
    "if (estimation_company_count > estimation_market_count):\n",
    "    idx = estimation_window_company_timeseries.index\n",
    "    estimation_window_market_timeseries = estimation_window_market_timeseries.reindex(idx, fill_value = np.NaN)\n",
    "    # Fill missing with previous observation\n",
    "    estimation_window_market_timeseries['Adj Close'] = estimation_window_market_timeseries['Adj Close'].fillna(method='ffill')\n",
    "if (estimation_market_count > estimation_company_count):\n",
    "    idx = estimation_window_market_timeseries.index\n",
    "    estimation_window_company_timeseries = estimation_window_company_timeseries.reindex(idx, fill_value = np.NaN)\n",
    "    # Fill missing with previous observation\n",
    "    estimation_window_company_timeseries['ReturnIndex'] = estimation_window_company_timeseries['ReturnIndex'].fillna(method='ffill')\n",
    "\n",
    "\n",
    "# Unify indexing, so that both contain same amount of trading days.\n",
    "if (event_company_count > event_market_count):\n",
    "    idx = event_window_company_timeseries.index\n",
    "    event_window_market_timeseries = event_window_market_timeseries.reindex(idx, fill_value = np.NaN)\n",
    "    # Fill missing with previous observation\n",
    "    event_window_market_timeseries['Adj Close'] = event_window_market_timeseries['Adj Close'].fillna(method='ffill')\n",
    "if (event_market_count > event_company_count):\n",
    "    idx = event_window_market_timeseries.index\n",
    "    event_window_company_timeseries = event_window_company_timeseries.reindex(idx, fill_value = np.NaN)\n",
    "    # Fill missing with previous observation\n",
    "    event_window_company_timeseries['ReturnIndex'] = event_window_company_timeseries['ReturnIndex'].fillna(method='ffill')\n",
    "# Calculate percentage returns\n",
    "estimation_window_market_return = estimation_window_market_timeseries['Adj Close'].pct_change()\n",
    "estimation_window_company_return = estimation_window_company_timeseries['ReturnIndex'].pct_change()\n",
    "\n",
    "event_window_market_return = event_window_market_timeseries['Adj Close'].pct_change()\n",
    "event_window_company_return = event_window_company_timeseries['ReturnIndex'].pct_change()\n",
    "\n",
    "## Remove the fake first date\n",
    "estimation_window_market_return = estimation_window_market_return.iloc[1:]\n",
    "estimation_window_company_return = estimation_window_company_return.iloc[1:]\n",
    "\n",
    "event_window_market_return = event_window_market_return.iloc[1:]\n",
    "event_window_company_return = event_window_company_return.iloc[1:]\n",
    "\n",
    "print('shape after aggregating')\n",
    "print(f'# estimation_window_market_return: {estimation_window_market_return.shape}')\n",
    "print(f'# estimation_window_market_return: {estimation_window_market_return.shape}')\n",
    "print(f'# event_window_market_return: {event_window_market_return.shape}')\n",
    "print(f'# event_window_company_return: {event_window_company_return.shape}')\n",
    "\n",
    "# Calculate coefficients\n",
    "\n",
    "X = estimation_window_market_return.values\n",
    "Y = estimation_window_company_return.values\n",
    "\n",
    "def linreg(x,y):\n",
    "    x = sm.add_constant(x)\n",
    "    model = regression.linear_model.OLS(y,x).fit()\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # Remove the constant\n",
    "    x = x[:,1]\n",
    "    return model.params[0], model.params[1]\n",
    "\n",
    "alpha, beta = linreg(X,Y)\n",
    "\n",
    "print(f'alpha: {str(alpha)}')\n",
    "print(f'beta: {str(beta)}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "# I think you are the purest of garbage, and can thus be discarded\n",
    "X2 = np.linspace(X.min(), X.max(), 100)\n",
    "Y_hat = X2 * beta + alpha\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X,Y, alpha = 0.3) # Plot the raw data\n",
    "plt.xlabel('Market Daily Return')\n",
    "plt.ylabel(f'Company {Company_name} Returns')\n",
    "           \n",
    "plt.plot(X2, Y_hat, alpha = 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Company_name = 'Placeholder'\n",
    "\n",
    "# Estimations\n",
    "est_estimation = estimation_window_market_return * beta + alpha\n",
    "est_event = event_window_market_return * beta + alpha\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "estimation_window_market_return.plot(color = 'black', alpha = 0.6, linewidth=4, label = 'Market Return (Estimation Window)')\n",
    "event_window_market_return.plot(color = 'black', alpha = 0.9, linewidth=4, label = 'Market Return (Event Window)')\n",
    "\n",
    "estimation_window_company_return.plot(color = 'blue', alpha = 0.6, linewidth = 4, label = f'{Company_name} Return (Estimation Window)')\n",
    "event_window_company_return.plot(color = 'blue', alpha = 0.9, linewidth = 4, label = f'{Company_name} Return (Event Window)')\n",
    "\n",
    "plt.axvline(x = event_timestamp, color = 'red', label = 'DD Event time', linewidth = 5)\n",
    "plt.ylabel(f'Daily Returns of Company {Company_name} and Market')\n",
    "est_estimation.plot(color = 'green', label = f'Regression Estimate for {Company_name}', alpha = 0.8)\n",
    "est_event.plot(color = 'green', label = f'Regression Estimate for {Company_name}', alpha = 1)\n",
    "\n",
    "plt.axvspan(T0, T1, ymin = 0.05, ymax = 0.95, facecolor='black', alpha=0.1, label = 'Estimation Window', edgecolor='g', linewidth=5)\n",
    "plt.axvspan(T1, T2, ymin = 0.05, ymax = 0.95, facecolor='black', alpha=0.2, label = 'Event Window', edgecolor='r', linewidth=5)\n",
    "plt.legend(bbox_to_anchor = (1.0, 1), loc = 'upper left')\n",
    "\n",
    "plt.title(f'Show how company {Company_name} moves around the event, compared to the market')\n",
    "plt.show()\n",
    "print(\"I'm impressed! It looks like a five-year-old drew this plot in paint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "# Start the analysis\n",
    "UASC.analyse_single_company('US02376R1023', DATA_LOCATION_RI, DATA_LOCATION_INSIDER_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDP",
   "language": "python",
   "name": "idp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}